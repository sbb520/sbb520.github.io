<?xml version="1.0" encoding="UTF-8"?><rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Sbb-Blog</title>
        <description>欢迎来到sbb的博客，本人程序员一个，专注后端相关的技术。</description>
        <link>/</link>
        <atom:link href="//feed.xml" rel="self" type="application/rss+xml" />
        <pubDate>2019-10-03 06:10:47</pubDate>
        <lastBuildDate>2019-10-03 06:10:47</lastBuildDate>
        <generator>Gitblog v1.0</generator>
                <item>
            <title>统计学：概率论</title>
            <description>
            &lt;!--
author: sbb
head: http://pingodata.qiniudn.com/jockchou-avatar.jpg
date: 2019-10-02
title: 统计学：概率论
tags: statistics probability
images: http://pingodata.qiniudn.com/cube2.jpg
category: statistics
status: publish
summary: 最近对数据分析有点兴趣，所以准备好好地学习统计学，而概率论支持着很多统计学的理论，因此概率论是非常重要的一门学科。
--&gt;
&lt;p&gt;最近对数据分析有点兴趣，所以准备好好地学习统计学，而概率论支持着很多统计学的理论，因此概率论是非常重要的一门学科。&lt;/p&gt;
&lt;h2&gt;1. 基本概念&lt;/h2&gt;
&lt;h3&gt;&lt;strong&gt;互斥与不互斥&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;一般而言，互斥与不互斥是针对&lt;strong&gt;某次事件&lt;/strong&gt;的发生结果而言。&lt;/p&gt;
&lt;p&gt;互斥：事件A和事件B不可能同时发生，那么称事件&lt;strong&gt;A和B互斥&lt;/strong&gt;（mutually exclusive）。反之则&lt;strong&gt;不互斥&lt;/strong&gt;（not mutually exclusive）。&lt;/p&gt;
&lt;p&gt;例如说抽一张扑克牌，这张牌不可能既是“&lt;strong&gt;黑桃&lt;/strong&gt;”又是“&lt;strong&gt;红心&lt;/strong&gt;”，因此两种事件，也就是2种事件&lt;strong&gt;互斥&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/statistics/probability/mutually_exclusive.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;但针对“&lt;strong&gt;黑桃&lt;/strong&gt;”，“&lt;strong&gt;数字3&lt;/strong&gt;”这两个事件，是有可能同时发生的，因此这两种事件不是互斥的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/statistics/probability/not_mutually_exclusive.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;独立与不独立&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;独立与不独立一般是针对&lt;strong&gt;两个事件&lt;/strong&gt;（A和B）之间的独立性，如果事件A的发生不受事件B的影响，那么就是&lt;strong&gt;独立事件&lt;/strong&gt;(independent event)，如投两次硬币，第一次的结果不会影响到第二次，否则就是&lt;strong&gt;非独立事件&lt;/strong&gt;(dependent event)，如学历与收入，抽到的牌是黑桃和数字。&lt;/p&gt;
&lt;h2&gt;2. 常见概念&lt;/h2&gt;
&lt;p&gt;下面介绍几种概率论里面必要的概念。&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;联合概率&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;联合概率（joint probability），用P(AB)来表示，表示A和B共同发生的概率。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;对于独立事件：P(AB) = P(A) * P(B)&lt;/p&gt;
&lt;p&gt;对于非独立事件：P(AB) = P(A|B) &lt;em&gt; P(B) = P(B|A) &lt;/em&gt; P(A)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;&lt;strong&gt;条件概率&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;条件概率（conditional probability），也叫后验概率，也就是某个事件（设A）在另一个事件（设B）已发生的情况下，发生的概率，用P(A|B)表示：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;对于独立事件：P(A|B) = P(A)&lt;/p&gt;
&lt;p&gt;对于非独立事件：P(A|B) = P(AB) / P(B) &lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;&lt;strong&gt;随机变量&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;随机变量（random variable）是指随机事件的发生数量，其中分为离散型（discrete）和连续型（continuous）。&lt;/p&gt;
&lt;p&gt;离散型是指发生的事件在一定区间内的取值是有限个。&lt;/p&gt;
&lt;p&gt;如掷骰子，只有1，2，3，4，5，6这四种情况。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://gss1.bdstatic.com/9vo3dSag_xI4khGkpoWK1HF6hhy/baike/s%3D250/sign=680634bb828ba61edbeecf2a713497cc/d1160924ab18972b0d3432bbe6cd7b899e510ab0.jpg&quot; alt=&quot;随机变量&quot; /&gt;&lt;/p&gt;
&lt;p&gt;连续型是指一定区间可以取无数个，如人的身高，可以取身高曲线上的某个点。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://gss0.bdstatic.com/94o3dSag_xI4khGkpoWK1HF6hhy/baike/s%3D220/sign=634ebfcaf736afc30a0c38678319eb85/0bd162d9f2d3572c71de6ed68a13632762d0c3f8.jpg&quot; alt=&quot;正态分布研究图3&quot; /&gt;&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;期望值&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;期望值（expected value）就是随机实验进行很多次，得到的全部值的平均值，就是期望值E(x)，如掷骰子，期望值计算如下：&lt;/p&gt;
&lt;p&gt;![](/blog/img/statistics/probability/expected value example.svg)&lt;/p&gt;
&lt;p&gt;一般而言，对于离散型的变量，我们用以下公式计算：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/statistics/probability/expected_value_discrete_formula.svg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;而针对连续型的变量，我们一般会根据他的概率函数做一个密度（微积分）计算从而得出期望值。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/statistics/probability/expected_value_continuous_formula.svg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;方差&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;方差（variance）用来表示个体数据的离散程度，有时候也用σ^2来表示，计算方式如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/statistics/probability/variance_formula.svg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;具体原理就是累加每个值于平均值的距离，至于为什么要用平方来计算单个的距离值，因为距离可以是正和负，平方值的话可以解决这个问题。&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;标准差&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;标准差（standard deviation）就是对方差进行平方，这里不做详细描述。&lt;/p&gt;
&lt;h2&gt;3. 贝叶斯定理&lt;/h2&gt;
&lt;p&gt;贝叶斯定理（Bayes' theorem）用于计算在某个事情（如A）下，某个事情（如B）发生的概率。&lt;/p&gt;
&lt;p&gt;可以理解为基本用于非独立事件之间的条件概率计算，公式如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/statistics/probability/Bayes_theorem1.svg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;有些还会把P(B)单独拆分，变成如下样子：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/statistics/probability/Bayes_theorem2.svg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;从根本上来说，贝叶斯定理就是在已知&lt;strong&gt;先验概率&lt;/strong&gt;(设P(A))以及某些&lt;strong&gt;特定条件概率&lt;/strong&gt;的情况下，计算&lt;strong&gt;后验概率&lt;/strong&gt;（条件概率P(A|B)）。&lt;/p&gt;
&lt;p&gt;设你去省医院检查，医院结果显示你呈弱阳性，进一步的结果需要送到国家级的医院进行进一步的检查，但你可能已经吓到半死了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/statistics/probability/bayes_theorem_example1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;但你不太死心，感觉自己平时生活习惯良好，不太可能患上XX癌症呀，于是拼命上各种论坛去查案例，发现了一张最新的国家医院体检统计如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;事件&lt;/th&gt;
&lt;th&gt;概率&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;xx癌症患病的人，设A&lt;/td&gt;
&lt;td&gt;1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;省医院结果为阳性的概率，设B&lt;/td&gt;
&lt;td&gt;10%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;患有xx癌症的人，其结果为阳性的概率，设B|A&lt;/td&gt;
&lt;td&gt;90%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;体检结果为阳性，其患有xx癌症的概率，设A|B&lt;/td&gt;
&lt;td&gt;?%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;根据贝叶斯概率计算，你的患病概率为&lt;strong&gt;P(A|B) = P(A) * P(B|A) / P(B) = 9%&lt;/strong&gt;，然后你可以相对来说送一口气。毕竟看上去没有那么吓人了，这是因为你知道了阳性的结果，且不是全部的阳性都是患病，他们是有交集的。求得P(A|B)其实就是求橙色部分在绿色部分的面积。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/statistics/probability/bayes_theorem_example2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;上面的例子可能不太恰当，但在现实生活，有很多的医学上会用到贝叶斯定理，比如说问你判断你是否患有癌症，先问你是否喉咙痛，根据以往的记录喉咙痛的话患癌症的概率会大幅度提高，其实作用就是不停地通过各种条件去细化这个概率。&lt;/p&gt;
&lt;h2&gt;4. 二项分布&lt;/h2&gt;
&lt;p&gt;二项分布（binomial distribution）是由n次的独立的伯努利实验中成功的离散概率分布，那么伯努利实验又是什么呢？&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;伯努利分布&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;其实伯努利实验很简单，就是每次事件出现的结果只有互斥的两种，例如投硬币，这就是一个典型的伯努利实验，一般伯努利实验会设出现的结果为&lt;strong&gt;失败（0）和成功（1）&lt;/strong&gt;，随机变量出现1的概率为&lt;strong&gt;p&lt;/strong&gt;，出现0的概率为&lt;strong&gt;1-p&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;伯努利分布长这样子：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/statistics/probability/Bernoulli_distribution.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;举个例子：&lt;/p&gt;
&lt;p&gt;某人打靶，成功的概率为0.8，失败的概率为0.2，那么这个分布图就和上面展示的一样了。&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;二项分布&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;二项分布就是做n次伯努利实验，统计成功的次数和概率，根据两个参数画出分布图。&lt;/p&gt;
&lt;p&gt;一般人们会用这个公式去计算&lt;strong&gt;n次实验中，成功k次的概率&lt;/strong&gt;的概率，其中&lt;strong&gt;成功概率为p&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/statistics/probability/binomial_distribution_formula.svg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;其中公式中的(n k)是代表组合。&lt;/p&gt;
&lt;p&gt;举个例子，设我投6次硬币，投出3次正面的概率根据上面的计算为0.3125。&lt;/p&gt;
&lt;p&gt;然后我会整理出现1，2，3，4，5，6次正面的概率，并把它们列成图形，就会下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/statistics/probability/binomial_distribution.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h2&gt;6. 泊松分布&lt;/h2&gt;
&lt;p&gt;泊松分布（possion distribution）用于描述单位时间内随机事件发生次数的概率分布。公式如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/statistics/probability/possion_distribution.svg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;一般用来统计独立且概率是离散型的事件。&lt;/p&gt;
&lt;p&gt;如商场一天之内平均销售10个名牌手袋，请问一天之内售出11个名牌手袋的概率是多少？根据泊松分布，我们可以轻易算出概率为0.1137。&lt;/p&gt;
&lt;h2&gt;7. 指数分布&lt;/h2&gt;
&lt;p&gt;指数分布（exponential distribution）用以算出独立事件发生的时间间隔。计算的公式如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/statistics/probability/exponential_distribution_formula.svg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;如某个商店平均每小时卖出3个手袋，那么请问半小时内能卖出手袋的概率是多少？&lt;/p&gt;
&lt;p&gt;所算的概率就是P(x&amp;lt;= 1/2 ) = 1 - e^(-3*1/2) = 0.7769&lt;/p&gt;
&lt;h2&gt;8. 正态分布&lt;/h2&gt;
&lt;p&gt;现实生活中，很多事件的总体（如人的身高）都会遵守着一个正态分布。很多正面和负面的因素累加起来，会使得总体样本的数据趋向于正态分布。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;根据中心极限定理，如果一个事物受到多种因素的影响，不管每个因素本身是什么分布，它们加总后，结果的平均值就是正态分布。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/statistics/probability/normal_distribution_example1.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;要注意的是，正态分布是用于处理连续型的概率，刚刚所介绍的分布都是处理离散型的概率。&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;定义&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;若随机变量X服从一个数学期望为μ，方差为σ^2的正态分布。&lt;/p&gt;
&lt;p&gt;则记为&lt;strong&gt;N(μ, σ^2)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;其中μ决定了正态分布的位置，σ决定了正态分布的幅度。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/statistics/probability/normal_distribution_schema.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;其概率密度函数为&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/statistics/probability/normal_distribution_value_formula.svg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;公式的意义就是计算抽取的值低于或等于x的概率是多少。&lt;/p&gt;
&lt;p&gt;如下图，我们可以用这个公式计算得出下面正态分布，值小于或等于0的概率为0.5&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/statistics/probability/normal_distribution_schema2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;数据标准化&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;在说标准化正态分布之前，有必要先了解一下数据标准化的意义，因为网上很多文章没有说明白这个概念。之所以要进行数据标准化，其实是可以把数据放在&lt;strong&gt;同一个标准&lt;/strong&gt;下面，可以方便比对。其中有一种著名的方法叫做z-score，标准化完之后，整体会服从平均值为0，标准差为1，公式如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/statistics/probability/z-score.svg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;举个例子，某次考试有英语和语文，小明考了70分语文，90分英语，按照常理来说，会说小明的英语比语文要好，但是如果那天的考试语文很难，大部分学生只有50-60分，英语却很简单，大部分人都有90分，那么我们要怎么说明白小明的语文要比英语好呢？&lt;/p&gt;
&lt;p&gt;而z-score就考虑到了总体的平均值（μ）和离散程度（σ）。从而计算出更加合理的分数机制。&lt;/p&gt;
&lt;p&gt;下图引用漫画统计学的一个例子，一个人历史得了73分，一个人生物得到73分，可以通过标准分来对比之间的价值。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/statistics/probability/z-score_example.png&quot; alt=&quot;1569994965678&quot; /&gt;&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;标准化正态分布&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;标准化正态分布就是服从N(0,1)的正态分布，且值和对应的概率如下表所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/statistics/probability/standard_normal_distribution_possibility.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;这是因为如果使用概率密度函数来计算概率的话，在以前没有计算机的时代是基本不敢想象的。旧时的人们想了一个方法，就是把要统计的数据标准化一下，再去根据上面的标准化正态表的值对应的概率，可以比较方便知道概率是多少了。&lt;/p&gt;
&lt;p&gt;以下例子转载自数学乐&lt;/p&gt;
&lt;p&gt;例子：求总体在 0 和 0.45 之间的百分比&lt;/p&gt;
&lt;p&gt;在 0.4 的行开始，向右去到 0.45 ，来找到 0.1736 这个值0.1736 是 &lt;strong&gt;17.36%&lt;/strong&gt;，所以总体的 17.36% 是在离平均值 0 到 0.45个标准差之间。 &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.shuxuele.com/data/images/standard-normal-distribution-0-45.gif&quot; alt=&quot;标准正态分布 0.45 = 0.1736&quot; /&gt;&lt;/p&gt;
&lt;p&gt;因为曲线是对称的，我们可以用这个表来查看负值：−0.45 的面积也是 0.1736。&lt;/p&gt;
&lt;p&gt;更详细的计算可以去&lt;a href=&quot;https://www.shuxuele.com/data/standard-normal-distribution-table.html&quot;&gt;这里&lt;/a&gt;看，计算的过程稍微想一下就明白了。&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;连续性修正&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;但是如果二项分布的实验次数相对较大，那么可以用&lt;strong&gt;连续性修正&lt;/strong&gt;来接近正态分布，从而方便计算概率，这里就不详细说明了。。&lt;/p&gt;
&lt;p&gt;参考资料：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;维基百科&lt;/li&gt;
&lt;li&gt;百度百科&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.shuxuele.com/data/standard-normal-distribution-table.html&quot;&gt;数学乐-标准正态分布&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;统计学-日本学习漫画&lt;/li&gt;
&lt;li&gt;深入浅出统计学(headfirst)&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.ruanyifeng.com/blog/2017/08/normal-distribution.html&quot;&gt;正态分布--阮一峰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/vamei/p/3198371.html&quot;&gt;vamei博客&lt;/a&gt;  &lt;/li&gt;
&lt;/ol&gt;            </description>
            <pubDate>2019-10-02 10:20:41</pubDate>
            <link>//blog/Statistics/probability.html</link>
            <guid isPermaLink="true">//blog/Statistics/probability.html</guid>
                                               <category>statistics</category>
                                    </item>
                <item>
            <title>服务器的两种并发原理</title>
            <description>
            &lt;!--
author: sbb
head: http://pingodata.qiniudn.com/jockchou-avatar.jpg
date: 2018-11-7
title: 服务器的两种并发原理
tags: server
images: http://pingodata.qiniudn.com/cube2.jpg
category: server
status: publish
summary: 服务器实现并发的两种方式。
--&gt;
&lt;p&gt;众所周知，现在的服务器可以处理多个socket连接，背后并发的实现主要有两种途径。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;多线程同步阻塞&lt;/li&gt;
&lt;li&gt;I/O多路复用&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;socket的建立&lt;/h2&gt;
&lt;p&gt;聊到socket，就不得不提到socket的建立的流程。祭出经典的老图：
&lt;img src=&quot;/blog/img/server/1.png&quot; alt=&quot;jpg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;服务器依次使用&lt;font color=red&gt;socket，bind，listen&lt;/font&gt;之后就会监听对应的地址，此时&lt;font color=red&gt;accept&lt;/font&gt;会一直阻塞直到有连接建立，如果客户端和服务器建立了连接，那么&lt;font color=red&gt;accept&lt;/font&gt;就会返回一个连接句柄，可以对连接进行读数据或者写数据。&lt;/p&gt;
&lt;h4&gt;同步阻塞&lt;/h4&gt;
&lt;p&gt;那么问题来了，服务器如果不做特殊处理的话，一次只能处理一个连接，新的连接来是需要等待上一个连接结束才能连接成功，这就是最开始的服务器同步阻塞方法。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;同步阻塞：进程发起IO系统调用后，进程被阻塞，转到内核空间处理，整个IO处理完毕后返回进程。操作成功则进程获取到数据。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/server/2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h2&gt;多线程并发&lt;/h2&gt;
&lt;p&gt;可能以前的拥有的电脑人不多，这种方式一次只能连接一个倒也没有问题，之后访问的人开始多起来，设计者觉得这样下去不行，就设计了多线程同步阻塞的方法。每次accept获得一个句柄，就创建一个线程去处理连接，这下子就能同时处理多个连接呢。这就是经典的多线程同步阻塞的方法。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;典型的多线程（进程）并发模型就是&lt;font color=red&gt;cgi&lt;/font&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;特点&lt;/h4&gt;
&lt;p&gt;服务器和客户端之间的并发，有以下特点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;外部连接很多，但很多连接是不活跃的连接，典型的如聊天的im系统。&lt;/li&gt;
&lt;li&gt;少量的CPU消耗。&lt;/li&gt;
&lt;li&gt;大部分的时间耗费在I/O阻塞和其他网络服务。&lt;/li&gt;
&lt;li&gt;外部网络不稳定，客户端收发数据慢很多。&lt;/li&gt;
&lt;li&gt;对业务的请求处理很快，大部分时候毫秒级就可以完成。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;问题&lt;/h4&gt;
&lt;p&gt;根据以上特点，我们可以得知服务器有以下问题：
如果采用多线程同步阻塞，1个tcp连接需要建立1个线程，10k个连接需要建立10k个连接，然而大部分连接是不活跃，即便是需要处理业务逻辑，也可以快速返回结果，大部分时间也是处于I/O阻塞或网络等待。这就使得多个线程的创建很耗费资源，且线程的切换也是极其耗费CPU，这就很可能导致了CPU处理业务的消耗的资源不多，但是却花了很多资源在进程切换上面。&lt;/p&gt;
&lt;h2&gt;I/O多路复用&lt;/h2&gt;
&lt;p&gt;多线程并发的问题是大部分socket都是闲置的状态或者是处于IO阻塞的状态，那能不能把阻塞的socket先扔到一边去处理其他事情，来避免等待所带来的资源耗费，也就是非阻塞IO的概念。&lt;/p&gt;
&lt;h4&gt;非阻塞IO&lt;/h4&gt;
&lt;p&gt;当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;因此：使用非阻塞IO是需要不断轮询IO数据是否好了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;IO多路复用原理就是不断轮询多个socket，当其中的某个socket准备好了数据就返回，否则整个进程继续阻塞，就可以让一个进程在不太耗费资源的情况下处理多个连接，但是这个轮询的操作是交给内核态去完成，也就避免了内核态和用户态的切换的问题。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;而目前的实现方法有select, poll, epoll，其中epoll的性能最好，用的也是最广泛。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;优点&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;避免了创建多个线程所耗费的资源以及时间。&lt;/li&gt;
&lt;li&gt;对socket的轮询是内核态的完成，不需要像多线程那样切换需要耗费资源。  &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;br&gt;
而epoll的实现可以做到性能几乎不受连接数（单单是连接而没有其他的操作）的影响。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/server/3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;当然多路复用IO也有自己的问题，也就是本身不支持多核的使用，需要另外解决多核的利用。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;其中使用enroll的成熟程序有nginx，redis，nodej等。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;服务器的发展&lt;/h2&gt;
&lt;p&gt;根据&lt;a href=&quot;https://www.zhihu.com/question/64727674/answer/225113965&quot;&gt;知乎大佬的介绍&lt;/a&gt;，服务器经过发展可以分为两阶段：&lt;/p&gt;
&lt;h4&gt;第一代服务器模型&lt;/h4&gt;
&lt;p&gt;把传输层的tcp并发的连接放到IO多路复用去处理，应用层继续使用多线程并发模型去做。这样就可以大幅度减少线程的创建切换的资源耗费。&lt;br /&gt;
如：nginx + php-fpm（其实是php-fpm是多进程）&lt;/p&gt;
&lt;h4&gt;第二代服务器模型&lt;/h4&gt;
&lt;p&gt;第二代服务器模型是把应用层也使用IO多路复用去处理，减少应用层的等待外部接口调用阻塞等待，一般是大厂大流量并发需要用到。&lt;br /&gt;
如：  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;nodejs的异步回调  &lt;/li&gt;
&lt;li&gt;Go的goroutine&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;br&gt;&lt;br /&gt;
参考资料：&lt;br /&gt;
[1]：&lt;a href=&quot;https://www.zhihu.com/question/64727674/answer/225113965&quot;&gt;许怀远的知乎回答&lt;/a&gt;&lt;br /&gt;
[2]：&lt;a href=&quot;https://segmentfault.com/a/1190000003063859&quot;&gt;Linux IO模式及 select、poll、epoll详解&lt;/a&gt;&lt;/p&gt;            </description>
            <pubDate>2019-10-01 09:05:00</pubDate>
            <link>//blog/server/1.html</link>
            <guid isPermaLink="true">//blog/server/1.html</guid>
                                               <category>server</category>
                                    </item>
                <item>
            <title>RabbitMQ入门</title>
            <description>
            &lt;!--
author: sbb
head: http://pingodata.qiniudn.com/jockchou-avatar.jpg
date: 2018-5-21
title: RabbitMQ入门
tags: RabbitMQ 并发
images: http://pingodata.qiniudn.com/cube2.jpg
category: RabbitMQ
status: publish
summary: rabbitmq是一个消息代理系统，为应用提供一个通用得消息发布，接受平台，为应用提供非阻塞的消息系统，方便进行异步处理。
--&gt;
&lt;h2&gt;简介&lt;/h2&gt;
&lt;p&gt;rabbitmq是一个消息代理系统，为应用提供一个通用得消息发布，接受平台，为应用提供非阻塞的消息系统，方便进行异步处理。&lt;/p&gt;
&lt;h4&gt;优点&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;消息的可靠性。持久化消息，消息接受确认，消息重传等可靠机制。&lt;/li&gt;
&lt;li&gt;灵活的路由。交换机可以根据广播，或者根据路由键或匹配符匹配到不同的队列。&lt;/li&gt;
&lt;li&gt;高可用的集群。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;应用场景&lt;/h2&gt;
&lt;h4&gt;1.异步处理&lt;/h4&gt;
&lt;p&gt;减少用户对不必要的耗时操作的等待，处理结果以异步方式（邮件，消息推送）进行提醒。&lt;/p&gt;
&lt;h4&gt;2.应用解耦&lt;/h4&gt;
&lt;p&gt;当某个应用发展到一定规模的时候，需要把里面的模块分别拆出来进行解耦，而模块之间的通讯方式是多样的，常见的有rpc，消息队列，http请求。其中消息队列在内部模块通信是更为稳定。&lt;/p&gt;
&lt;h4&gt;3.流量削峰&lt;/h4&gt;
&lt;p&gt;如果突发遇到大量的数据请求的时候，服务器如果不做队列处理，一下子处理全部的请求，会很容易造成宕机，如果把请求的数据都放入队列里，之后再逐个逐个地进行处理，可以平缓地渡过流量高峰期。&lt;/p&gt;
&lt;h3&gt;工作方式&lt;/h3&gt;
&lt;p&gt;rabbitmq的工作方式如下，生产者（publisher）发送消息到交换机，交换机（exchange）根据自己的类型以及消息的路由键，路由到对应的队列里，队列分发消息到消费者（consumer）&lt;br /&gt;
&lt;img src=&quot;/blog/img/RabbitMQ/4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h2&gt;初尝rabbitmq&lt;/h2&gt;
&lt;p&gt;现在我们假设有这个场景，客服A需要发送客户的下单信息给库存人员B，客服A有一个订单信息发送器，库存人员B拥有消息接收器。&lt;br /&gt;
首先库存人员B建立连接并接受消息，伪代码：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 建立连接
conn, _ := amqp.Dial(&quot;amqp://localhost&quot;)
ch, _ := conn.Channel()
// 声明队列，不存在则创建，存在则不会进行任何操作
queue, _ := ch.QueueDeclare(&quot;order&quot;)
// 从队列里面获取消息
deliver, _ := ch.Consume(q.Name)
for d:= range deliver {
    // 输出消息主体
    log.Printf(&quot;B Received a message: %s&quot;, d.Body)
    // 返回获取成功标识给队列
    d.Ack(true)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;然后客服A也建立连接并发送消息，伪代码：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 建立连接
conn, _ := amqp.Dial(&quot;amqp://localhost&quot;)
ch, _ := conn.Chanenel()
// 声明队列，不存在则创建，存在则不会进行任何操作
queue, _ := ch.QueueDeclare(&quot;order&quot;)
// 发布消息
ch.Publish(
    q.Name, // 队列名字
    amqp.Publishing{
        Body:[]byte(&quot;new order&quot; + product.String()),
    })&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上面就是一种简单的直接通过队列进行连接的方法，可能会有人看出来，为什么没有交换机的参与，其实上面的操作其实是通过默认交换机进行消息传递，可以不指定交换机名字直接指定队列名字进行交互。&lt;/p&gt;
&lt;h2&gt;模块介绍&lt;/h2&gt;
&lt;p&gt;通过上面的简单例子，我们可以更进一步地了解到rabbitmq的工作方式，下面我会更详细地讲解各个模块。&lt;/p&gt;
&lt;h3&gt;消息&lt;/h3&gt;
&lt;p&gt;消息是通信内容的主体，消息对象有点像http的request，除了可以携带消息内容，还可以带有各种属性，如：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;ContentType（内容类型）&lt;/li&gt;
&lt;li&gt;ContentEncoding（内容编码）&lt;/li&gt;
&lt;li&gt;RemoteKey（路由键）&lt;/li&gt;
&lt;li&gt;DeliveryMode（ 投递模式，消息是否持久化）&lt;/li&gt;
&lt;li&gt;等等... &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;有些属性只是约定规范，如ContentType，ContentEncoding，需要程序自己做处理，有些属性rabbitmq会根据值来进行处理，如RemoteKey，交换机会根据消息的RemoteKey和自身的类型来决定投递到哪些队列，DeliveryMode可以决定是否持久化消息。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#消息投递
ch.Publish(
    &quot;&quot;,     # exchange名字，空为默认交换机
    key,    # routingkey 路由键
    false,  
    false,
    # 消息
    amqp.Publishing{
        DeliveryMode:amqp.Persistent,
        ContentType:&quot;text/plain&quot;,
        Body:[]byte(&quot;hello world&quot;),
    }) &lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;队列&lt;/h3&gt;
&lt;p&gt;队列是存储消息的主体，队列本身所拥有的一些属性：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Name 队列名字，不同的队列名字应该保持唯一性&lt;/li&gt;
&lt;li&gt;Durable  rabbitmq重启后，队列是否依旧存在，需要注意消息要持久化的要另外设置消息&lt;/li&gt;
&lt;li&gt;exclusive 当前队列只能被一个消费者连接使用，关闭连接后删除队列。&lt;/li&gt;
&lt;li&gt;auto-delete 最后一个消费者退订后删除队列。    &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在代码里面队列声明，如果队列不存在则新建队列，如果已存在相同名字的队列且属性不同的话则会报错。可以选择让系统自动生成队列，然后返回队列名字。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 队列声明，参数依次为name，Durable，auto-delete，exclusive，no-wait.args
amqp.QueueDeclare(&quot;queuename&quot;, true, false, flase, false, nil)&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;消费者（consumer）&lt;/h3&gt;
&lt;p&gt;消费者用以消费队列里的消息的自定义程序片段，消费者获取队列里的消息有两种方式，一种是拉取（pull）的方式，通过channel.basicget方法，一种是订阅方式，队列推送消息到rabbitmq，这种方式用的最多。&lt;/p&gt;
&lt;h3&gt;消息处理&lt;/h3&gt;
&lt;p&gt;消息处理，消费者端连接队列后，可以得到一个类似于句柄的东西，如果没有消息就会一直阻塞。&lt;br /&gt;
消费者在收到消息之后处理的情况可能是成功的，也有可能是失败的，为了确保消息已经成功处理然后队列删除消息，如果失败则进行其他机制，以免消息一直重复在队列里面，或消息因消费者宕机而丢失。&lt;/p&gt;
&lt;h4&gt;消息确认（ack）&lt;/h4&gt;
&lt;p&gt;如果消息成功地被消费者处理的话，需要有一个消息确认的机制。&lt;br /&gt;
rabbitmq提供两种确认机制：   &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;自动确认模式，队列将消息发送给消费者之后立即删除消息（basic.deliver或basic.get-ok）&lt;/li&gt;
&lt;li&gt;显式确认模式，待消费者发送接受成功之后删除（basic.ack）  &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;一般而言我们用的更多的是显式确认模式，如果消费者接收到消息没有进行确认之后就宕机了，队列里面的该消息还是会存在的，然后会把消息转发到其他消费者。&lt;/p&gt;
&lt;h4&gt;消息拒绝（basic.reject）&lt;/h4&gt;
&lt;p&gt;如果消费者对消息的处理出现了一些问题，可以调用rabbitmq的basic.reject来拒绝消息，拒绝消息之后，可以做的是把消息放回到队列里面，或者直接删除消息。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;其实如果出现问题的消息，即便是交给其他的消费者，很会很大概率继续出现问题，这时候我们可以把消息放到其他专门处理记录问题的队列里面，交由另外的消费者处理。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;交换机&lt;/h3&gt;
&lt;p&gt;交换机更像是消息的路由层，队列绑定到交换机，然后发布者可以发送的消息都是经过交换机的，然后经由消息的remote key（路由键）路由到交换机所绑定的队列里。
交换机分为4种类型：&lt;/p&gt;
&lt;h4&gt;1.直连交换机（direct）&lt;/h4&gt;
&lt;p&gt;直连型交换机（direct exchange）是根据消息携带的路由键（routing key）将消息投递给对应队列的。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;将一个队列绑定到某个交换机上，同时赋予该绑定一个路由键（routing key）&lt;/li&gt;
&lt;li&gt;当一个携带着路由键为R的消息被发送给直连交换机时，交换机会把它路由给绑定值同样为R的队列。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;其实初尝rabbitmq的例子里面，看上去没有绑定交换机，实际上也是绑定了直连交换机，只是是一个特殊的预先声明好的，名字为空字符串的交换机，叫默认交换机，每个队列都会自动绑定到默认交换机上。&lt;br /&gt;
&lt;img src=&quot;/blog/img/RabbitMQ/1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h4&gt;2.扇形交换机（funout）&lt;/h4&gt;
&lt;p&gt;扇型交换机（funout exchange）将消息路由给绑定到它身上的所有队列，而不理会绑定的路由键。如果N个队列绑定到某个扇型交换机上，当有消息发送给此扇型交换机时，交换机会将消息的拷贝分别发送给这所有的N个队列。扇型用来交换机处理消息的&lt;font color=red&gt;广播路由&lt;/font&gt;（broadcast routing）。&lt;br /&gt;
&lt;img src=&quot;/blog/img/RabbitMQ/2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h4&gt;3.主题交换机（topic）&lt;/h4&gt;
&lt;p&gt;主题交换机（topic exchanges）通过对消息的路由键和队列到交换机的绑定模式之间的匹配，将消息路由给一个或多个队列。主题交换机经常用来实现各种分发/订阅模式及其变种。主题交换机通常用来实现消息的多播路由（multicast routing）。&lt;br /&gt;
主题交换机在我看来就像添加了简单的&lt;font color=red&gt;通配符+字符串&lt;/font&gt;来达到一个路由的规则。&lt;br /&gt;
&lt;img src=&quot;/blog/img/RabbitMQ/3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h4&gt;4.头交换机（headers）&lt;/h4&gt;
&lt;p&gt;头交换机用的不是很多，有时消息的路由操作会涉及到多个属性，此时使用消息头就比用路由键更容易表达，头交换机（headers exchange）就是为此而生的。头交换机使用多个消息属性来代替路由键建立路由规则。通过判断消息头的值能否与指定的绑定相匹配来确立路由规则。&lt;/p&gt;
&lt;h2&gt;扇形路由器实现广播&lt;/h2&gt;
&lt;p&gt;生产者代码&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conn, _ := amqp.Dial(&quot;amqp://localhost&quot;)

ch, _ := conn.Channel()

ch.ExchangeDeclare(
    &quot;hello&quot;,
    &quot;fanout&quot;,
    true,
    false,
    false,
    false,
    nil,
    )

ch.Publish(
    &quot;hello&quot;,
    &quot;&quot;,     // 由于是广播，所以可以不填写路由键
    false,
    false,
    amqp.Publishing{
        DeliveryMode:amqp.Persistent,
        Body:[]byte(&quot;hello&quot;+time.Now().String()),
    })&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;消费者代码&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conn, _ := amqp.Dial(&quot;amqp://localhost&quot;)

ch, _ := conn.Channel()

ch.ExchangeDeclare(
        &quot;hello&quot;,  // 交换机名字
        &quot;fanout&quot;, // 交换机类型
        true,     // durable
        false,    // autoDelete
        false,    // internal
        false,    // noWait
        nil,      // args
    )

q, _ := ch.QueueDeclare(
        &quot;&quot;, 
        false,  // durable
        false,  // autoDelete
        true,   // exclusive
        false,  // noWait
        nil,    //
        )

ch.QueueBind(
    q.Name,     // queuename 
    &quot;&quot;,         // remote key，由于是广播，可以不填写路由键
    &quot;hello&quot;,    // exchange name
    false,      // nowait
    nil,
    )

msgs, _ := ch.Consume(q.Name,&quot;&quot;, true, false, false,false,nil)

for msg := range msgs {
    log.Printf(&quot;%s&quot;, msg.Body)
}&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;主题交换机实现路由匹配&lt;/h2&gt;
&lt;p&gt;设有如下场景：设计一个日志收集系统，日志有不同的级别，debug，info，warn，error，日志格式为：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;级别.模块名字 如：info.login&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;有不同的队列负责收集不同级别的日志，其中有个队列专门收集收集warn和error的数据，设计如下：
生产者&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;func main() {
    conn, _ := amqp.Dial(&quot;amqp://localhost&quot;)

    ch, _ := conn.Channel()

    ch.ExchangeDeclare(
        &quot;logs&quot;,
        &quot;topic&quot;,
        true,
        false,
        false,
        false,
        nil,
    )

    ch.Publish(
        &quot;logs&quot;,
        &quot;debug.123&quot;,
        false,
        false,
        amqp.Publishing{
            DeliveryMode:amqp.Persistent,
            Body:[]byte(&quot;hello&quot;),
        },
    )
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;消费者&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;func main() {
    conn, _ := amqp.Dial(&quot;amqp://localhost&quot;)
    ch, _ := conn.Channel()

    ch.ExchangeDeclare(
        &quot;logs&quot;,
        &quot;topic&quot;,
        true,
        false,
        false,
        false,
        nil,
    )

    q, _ := ch.QueueDeclare(
        &quot;log1&quot;,
        true,
        false,
        false,
        false,
        nil,
    )

    // 队列绑定的remote key
    keys := []string{&quot;error.*&quot;, &quot;warn.*&quot;}

    for _, key := range keys{
        ch.QueueBind(
            q.Name,
            key,
            &quot;logs&quot;,
            false,
            nil,
        )
    }

    deliver, _ := ch.Consume(
        q.Name,
        &quot;&quot;,
        false,
        false,
        false,
        false,
        nil,
    )

    for d:= range deliver {
        fmt.Println(string(d.Body))
        d.Ack(true)
    }
}&lt;/code&gt;&lt;/pre&gt;            </description>
            <pubDate>2019-10-01 09:05:00</pubDate>
            <link>//blog/RabbitMQ/firstToLearn.html</link>
            <guid isPermaLink="true">//blog/RabbitMQ/firstToLearn.html</guid>
                                               <category>RabbitMQ</category>
                                    </item>
                <item>
            <title>如何做到资源并发安全</title>
            <description>
            &lt;!--
author: sbb
head: http://pingodata.qiniudn.com/jockchou-avatar.jpg
date: 2018-5-08
title: 如何做到资源并发安全
tags: Go 并发
images: http://pingodata.qiniudn.com/cube2.jpg
category: Go
status: publish
summary: 结合一些常见的做法，本文整理了一下如何做到并发安全。
--&gt;
&lt;h2&gt;并发安全&lt;/h2&gt;
&lt;p&gt;何为并发安全，就是多个并发体在同一段时间内访问同一个共享数据，共享数据能被正确处理。&lt;/p&gt;
&lt;h2&gt;并发不安全的后果&lt;/h2&gt;
&lt;p&gt;并发不安全最典型的案例就是卖票超售，设想有一家电影院，有两个售票窗口，售票员售票时候先看一下当前剩余票数是否大于0，如果大于0则售出票。&lt;br /&gt;
用伪代码就是如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 售票操作（一张票）
# 如果票数大于0
totalNum = getTotalNum()
if totalNum &amp;gt; 0
    # 则售出一张票
    totalNum = totalNum - 1
else
    failedToSold()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;看上去也没有什么问题，流程图如下:&lt;br /&gt;
&lt;img src=&quot;/blog/img/Go/SafeComplicate1.jpg&quot; alt=&quot;jpg&quot; /&gt;&lt;br /&gt;
此时票数剩下一张票，两个售票窗口同时来了顾客，两个售票人都看了一下剩余票数还有一张，不约而同地收下顾客的钱，余票还剩一张，但是却售出了两张票，就会出现致命的问题。&lt;br /&gt;
&lt;img src=&quot;/blog/img/Go/SafeComplicate2.jpg&quot; alt=&quot;jpg&quot; /&gt;  &lt;/p&gt;
&lt;h2&gt;如何做到并发安全&lt;/h2&gt;
&lt;p&gt;目前最最主流的办法就是加锁就行操作，其实售票的整个操作同时间内只能一个人进行，在我看来归根到底加锁其实就是让查询和售票两个步骤原子化，只能一块执行，不能被其他程序中断，让这步操作变成串行化。下面就介绍一下使查询和售票原子化的常见程序操作：&lt;/p&gt;
&lt;h2&gt;锁&lt;/h2&gt;
&lt;p&gt;锁的做法就是每次进入这段变量共享的程序片段，都要先获取一下锁，如果获取成功则可以继续执行，如果获取失败则阻塞，直到其他并发体把锁给释放，程序得到执行调度才可以执行下去。&lt;br /&gt;
锁本质上就是让并发体创建一个程序临界区，临界区一次只能进去一个并发体，伪代码示意如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lock()
totalNum = getTotalNum()
if totalNum &amp;gt; 0
    # 则售出一张票
    totalNum = totalNum - 1
else
    failedToSold()
unlock()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;顺带一提的是锁可以分为写锁与排它锁，一般如无特殊说明，一般锁都是指写锁。&lt;/p&gt;
&lt;h3&gt;读锁与写锁&lt;/h3&gt;
&lt;p&gt;读锁也叫共享锁，写锁也叫排它锁，锁的概念被发明了之后，人们就想着如果我很多个并发体大部分时间都是读，如果就把变量读取的时候也要建立临界区，那就有点太大题小做了。于是人们发明了读锁，一个临界区如果加上了读锁，其他并发体执行到相同的临界区都可以加上读锁，执行下去，但不能加上写锁。这样就保证了可以多个并发体并发读取而又不会互相干扰。&lt;/p&gt;
&lt;h2&gt;队列&lt;/h2&gt;
&lt;p&gt;队列也是解决并发不安全的做法。多个并发体去获取队列里的元素，然后进行处理，这种做法和上锁其实大同小异，本质都是把并发的操作串行化，同一个数据同一个时刻只能交给一个并发体去处理。&lt;br /&gt;
伪代码：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 第一个获取到队列的元素就可以进行下去
isCanSold = canSoldList.pop()
totalNum = getTotalNum()
if totalNum &amp;gt; 0
    # 则售出一张票
    totalNum = totalNum - 1
else
    failedToSold()&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;CAS&lt;/h2&gt;
&lt;p&gt;CAS（compare and swap），先比对，然后再进行交换，和数据库里的乐观锁的做法很相似。&lt;/p&gt;
&lt;h3&gt;乐观锁&lt;/h3&gt;
&lt;p&gt;数据库里的乐观锁并不是真的使用了锁的机制，而是一种程序的实现思路。&lt;br /&gt;
乐观锁的想法是，每次拿取数据再去修改的时候很乐观，认为其他人不会去修改这个数据，表另外维护一个额外版本号的字段。&lt;br /&gt;
查数据的时候记录下该数据的版本号，如果成功修改的话，会修改该数据的版本号，如果修改的时候版本号和查询的时候版本号不一致，则认为数据已经被修改过，会重新尝试查询再次操作。&lt;br /&gt;
设我们表有一个user表，除了必要的字段，还有一个字段version，表如下：  &lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;username&lt;/th&gt;
&lt;th&gt;money&lt;/th&gt;
&lt;th&gt;version&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;a&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;b&lt;/td&gt;
&lt;td&gt;20&lt;/td&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;这时候我们需要修改a的余额-10元，执行事务语句如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;while
    select @money = money, @version = version from user where username = a;
    if @money &amp;lt; 10
        print('余额成功')
        break
    # 扣费前的预操作
    paied()
    # 实行扣费
    update user set money = money - 10, version = version + 1 where username = a and version = @version
    # 影响条数等于1，证明执行成功
    if @@ROWCOUNT == 1
        print('扣费成功')
        break
    else
        rollback
        print('扣费失败，重新进行尝试')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;乐观锁的做法就是使用版本的形式，每次写数据的时候会比对一下最开始的版本号，如果不同则证明有问题。&lt;br /&gt;
CAS的做法也是一样的，在代码里面的实现稍有一点不同，由于SQL每条语句都是原子性，查询对应版本号的数据再更新的这个条件是原子性的。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;update user set money = money - 10, version = version + 1 where username = a and version = @version&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;但是在代码里面两条查询和赋值两个语句不是原子性的，需要有特定的函数让cpu底层把两个操作变成一个原子操作，在go里面有atomic包支持实现，是这样实现的：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;for {
    user := getUserByName(A)
    version := user.version
    paied()
    if atomic.CompareAndSwapInt32(&amp;amp;user.version, version, version + 1) {
        user.money -= 10
    } else {
        rollback()
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;atomic.CompareAndSwapInt32需要依次传入要比较变量的地址，旧变量的值，修改后变量的值，函数会判断旧变量的值是否与现在变量的地址是否相同，相同则把新变量的值写入到该变量。&lt;br /&gt;
CAS的好处是不需要程序去创建临界区，而是让CPU去把两个指令变成原子性操作，性能更好，但是如果变量会被频繁更改的话，重试的次数变多反而会使得效率不如加锁高。&lt;/p&gt;            </description>
            <pubDate>2019-10-01 09:05:00</pubDate>
            <link>//blog/Go/SafeComplicate.html</link>
            <guid isPermaLink="true">//blog/Go/SafeComplicate.html</guid>
                                               <category>Go</category>
                                    </item>
                <item>
            <title>Golang学习笔记：channel</title>
            <description>
            &lt;!--
author: sbb
head: http://pingodata.qiniudn.com/jockchou-avatar.jpg
date: 2018-4-26
title: Golang学习笔记：channel
tags: Go 并发
images: http://pingodata.qiniudn.com/cube2.jpg
category: Go
status: publish
summary: channel是go里的goroutine通信的主要工具，简述channel的基本使用技巧。 
--&gt;
&lt;h2&gt;channel&lt;/h2&gt;
&lt;p&gt;channel是goroutine之间的通信机制，它可以让一个goroutine通过它给另一个goroutine发送数据，每个channel在创建的时候必须指定一个类型，指定的类型是任意的。&lt;br /&gt;
使用内置的make函数，可以创建一个channel类型：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ch := make(chan int)&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;发送和接受&lt;/h2&gt;
&lt;p&gt;channel主要的操作有发送和接受：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 发送数据到channel
ch &amp;lt;- 1
// 从channel接受数据
x := &amp;lt;- ch&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如向channel发送数据的时候，该goroutine会一直阻塞直到另一个goroutine接受该channel的数据，反之亦然，goroutine接受channel的数据的时候也会一直阻塞直到另一个goroutine向该channel发送数据，如下面操作：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;func main() {
    ch := make(chan string)
    // 在此处阻塞，然后程序会弹出死锁的报错
    c &amp;lt;- &quot;hello&quot;
    fmt.Println(&quot;channel has send data&quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;正确的操作：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;func main() {
    ch := make(chan string)
    go func(){
        // 在执行到这一步的时候main goroutine才会停止阻塞
        str := &amp;lt;- ch
        fmt.Println(&quot;receive data：&quot; + str)
    }()
    ch &amp;lt;- &quot;hello&quot;
    fmt.Println(&quot;channel has send data&quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;说到channel的阻塞，就不得不说到有缓冲的channel。&lt;/p&gt;
&lt;h2&gt;带缓冲的channel&lt;/h2&gt;
&lt;p&gt;带缓冲的channel的创建和不带缓冲的channel（也就是上面用的channel）的创建差不多，只是在make函数的第二个参数指定缓冲的大小。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 创建一个容量为10的channel
ch := make(chan int, 10)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;带缓冲的channel就像一个队列，遵从先进先从的原则，发送数据向队列尾部添加数据，从头部接受数据。&lt;br /&gt;
&lt;img src=&quot;/blog/img/Go/channel1.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
&lt;p&gt;goroutine向channel发送数据的时候如果缓冲还没满，那么该goroutine就不会阻塞。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ch := make(chan int, 2)
// 前面两次发送数据不会阻塞，因为缓冲还没满
ch &amp;lt;- 1
ch &amp;lt;- 2
// goroutine会在这里阻塞
ch &amp;lt;- 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;反之如果接受该channel数据的时候，如果缓冲有数据，那么该goroutine就不会阻塞。&lt;/p&gt;
&lt;p&gt;channel与goroutine之间的应用可以想象成某个工厂的流水线工作，流水线上面有打磨，上色两个步骤（两个goroutine），负责打磨的工人生产完成后会传给负责上色的工人，上色的生产依赖于打磨，两个步骤之间的可能存在存放槽（channel），如果存放槽存满了，打磨工人就不能继续向存放槽当中存放产品，直到上色工人拿走产品，反之上色工人如果把存放槽中的产品都上色完毕，那么他就只能等待新的产品投放到存放槽中。&lt;/p&gt;
&lt;h4&gt;备注&lt;/h4&gt;
&lt;p&gt;其实在实际应用中，带缓冲的channel用的并不多，继续拿刚才的流水线来做案例，如果打磨工人生产速度比上色工人工作速度要快，那么即便再多容量的channel，也会迟早被填满然后打磨工人会被阻塞，反之如果上色工人生产速度大于打磨工人速度，那么有缓冲的channel也是一直处于没有数据，上色工人很容易长时间处于阻塞的状态。&lt;/p&gt;
&lt;p&gt;因此比较好的解决方法还是针对生产速度较慢的一方多加人手，也就是多开几个goroutine来进行处理，有缓冲的channel最好用处只是拿来防止goroutine的完成时间有一定的波动，需要把结果缓冲起来，以平衡整体channel通信。&lt;/p&gt;
&lt;h2&gt;单方向的channel&lt;/h2&gt;
&lt;p&gt;使用channel来使不同的goroutine去进行通信，很多时候都和消费者生产者模式很相似，一个goroutine生产的结果都用channel传送给另一个goroutine，一个goroutine的执行依赖与另一个goroutine的结果。&lt;br /&gt;
因此很多情况下，channel都是单方向的，在go里面可以把一个无方向的channel转换为只接受或者只发送的channel，但是却不能反过来把接受或发送的channel转换为无方向的channel，适当地把channel改成单方向，可以达到程序强约束的做法，类似于下面例子：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;fuc main(){
    ch := make(ch chan string)

    go func(out chan&amp;lt;- string){
        out &amp;lt;- &quot;hello&quot;
    }(ch)

    go func(in &amp;lt;-chan string){
        fmt.Println(in)
    }(ch)

    time.Sleep(2 * time.Second)
}&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;select多路复用&lt;/h2&gt;
&lt;p&gt;在一个goroutine里面，对channel的操作很可能导致我们当前的goroutine阻塞，而我们之后的操作都进行不了。而如果我们又需要在当前channel阻塞进行其他操作，如操作其他channel或直接跳过阻塞，可以通过select来达到多个channel（可同时接受和发送）复用。如下面我们的程序需要同时监听多个频道的信息：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;broadcaster1 := make(chan string) // 频道1
broadcaster2 := make(chan string) // 频道2
select {
    case mess1 := &amp;lt;-broadcaster1:
        fmt.Println(&quot;来自频道1的消息：&quot; + mess1)
    case mess2 := &amp;lt;-broadcaster2:
        fmt.Println(&quot;来自频道2的消息：&quot; + mess2)
    default:
        fmt.Println(&quot;暂时没有任何频道的消息，请稍后再来~&quot;)
        time.Sleep(2 * time.Second)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;select和switch语句有点相似，找到匹配的case执行对应的语句块，但是如果有两个或以上匹配的case语句，那么则会随机选择一个执行，如果都不匹配就会执行default语句块（如果含有default的部分的话）。&lt;/p&gt;
&lt;p&gt;&lt;font color=red&gt;值得注意的是，select一般配合for循环来达到不断轮询管道的效果，可能很多小伙伴想着写个在某个case里用break来跳出for循环，这是不行的，因为break只会退出当前case，需要使用return来跳出函数或者弄个标志位标记退出&lt;/font&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;var flag = 0
for {
    if flag == 1 {break}
    select {
        case message := &amp;lt;- user.RecMess :
            event := gjson.Get(string(message), &quot;event&quot;).String()
            if event == &quot;login&quot; {
                Login(message, user)
            }
            break
        case &amp;lt;- user.End :
            flag = 1
            break
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;关闭&lt;/h2&gt;
&lt;p&gt;channel可以接受和发送数据，也可以被关闭。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;close(ch)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;关闭channel后，所有向channel发送数据的操作都会引起panic，而被close之后的channel仍然可以接受之前已经发送成功的channel数据，如果数据全部接受完毕，那么再从channel里面接受数据只会接收到零值得数据。&lt;/p&gt;
&lt;p&gt;channel的关闭可以用来操作其他goroutine退出，在运行机制方面，goroutine只有在自身所在函数运行完毕，或者主函数运行完毕才会打断，所以我们可以利用channel的关闭作为程序运行入口的一个标志位，如果channel关闭则停止运行。&lt;/p&gt;
&lt;p&gt;无法直接让一个goroutine直接停止另一个goroutine，但可以使用&lt;font color=red&gt;通信&lt;/font&gt;的方法让一个goroutine停止另一个goroutine，如下例子就是程序一边运行，一边监听用户的输入，如果用户回车，则退出程序。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;func main() {
    shutdown := make(chan struct{})
    var n sync.WaitGroup
    n.Add(1)
    go Running(shutdown, &amp;amp;n) 
    n.Add(1)
    go ListenStop(shutdown, &amp;amp;n) 
    n.Wait()
}

func Running(shutdown &amp;lt;-chan struct{}, n *sync.WaitGroup) {
    defer n.Done()
    for {
        select {
        case &amp;lt;-shutdown:
            // 一旦关闭channel，则可以接收到nil。
            fmt.Println(&quot;shutdown goroutine&quot;)
            return
        default:
            fmt.Println(&quot;I am running&quot;)
            time.Sleep(1 * time.Second)
        }   
    }   
}

func ListenStop(shutdown chan&amp;lt;- struct{}, n *sync.WaitGroup) {
    defer n.Done()
    os.Stdin.Read(make([]byte, 1)) 
    // 如果用户输入了回车则退出关闭channel
    close(shutdown)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;利用channel关闭时候的传送的零值信号可以有效地退出其他goroutine，特别是关闭多个goroutine的时候，就不需要向channel传输多个信息了。&lt;/p&gt;            </description>
            <pubDate>2019-10-01 09:05:00</pubDate>
            <link>//blog/Go/channel.html</link>
            <guid isPermaLink="true">//blog/Go/channel.html</guid>
                                               <category>Go</category>
                                    </item>
                <item>
            <title>Golang学习笔记：goroutine</title>
            <description>
            &lt;!--
author: sbb
head: http://pingodata.qiniudn.com/jockchou-avatar.jpg
date: 2018-4-24
title: Golang学习笔记：goroutine 
tags: Go 并发
images: http://pingodata.qiniudn.com/cube2.jpg
category: Go
status: publish
summary: 简述goroutine的概念以及如何使用技巧。
--&gt;
&lt;h2&gt;1.goroutine&lt;/h2&gt;
&lt;p&gt;goroutine是go语言的并发体。在go语言里面能使用go关键字来实现并发。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;go func()&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;1.1 概念介绍&lt;/h3&gt;
&lt;p&gt;goroutine本质上是协程，我刚刚学习的时候就粗略地认为goroutine是线程，直到最近才开始搞明白goroutine的基本概念。  &lt;/p&gt;
&lt;h4&gt;&lt;font color=#2f8bdc&gt;并发&lt;/font&gt;&lt;/h4&gt;
&lt;p&gt;在很久以前，人们希望一个计算机（一个cpu）上能同时执行多项任务，让cpu在某段时间内进行分片，在某段很短时间内执行程序a，然后又迅速得切换到程序b去执行，让人们看起来就像是两个程序在同时进行，这就是&lt;font color=red&gt;并发&lt;/font&gt;。&lt;/p&gt;
&lt;h4&gt;&lt;font color=#2f8bdc&gt;进程&lt;/font&gt;&lt;/h4&gt;
&lt;p&gt;但是人们随之发现，cpu在切换程序的时候，如果不保存上一个程序的状态（也就是我们常说的context--上下文），直接切换下一个程序，就会丢失上一个程序的一系列状态，于是引入了&lt;font color=red&gt;进程&lt;/font&gt;这个概念，用以划分好程序运行时所需要的资源。因此进程就是一个程序运行时候的所需要的基本资源单位（也可以说是程序运行的一个实体）。&lt;/p&gt;
&lt;h4&gt;&lt;font color=#2f8bdc&gt;并行&lt;/font&gt;&lt;/h4&gt;
&lt;p&gt;如果一个电脑有多个cpu，每个cpu都有进程在运行，这就是并行。&lt;/p&gt;
&lt;h4&gt;&lt;font color=#2f8bdc&gt;用户态与内核态&lt;/font&gt;&lt;/h4&gt;
&lt;p&gt;为了防止用户程序做出一些危险的指令，如关机，更改系统变量，修改别的进程数据，系统分为两种运行状态，用户态以及内核态，用户态是我们的程序所在的状态，不能随便对内核的底层进行操作。如果我们需要使用内核的底层操作的时候，内核提供了一种调用内核的接口，我们调用这些接口也就是系统调用，在进行系统调用的时候，cpu会切换到内核态，才能执行内核的函数。&lt;/p&gt;
&lt;h4&gt;&lt;font color=#2f8bdc&gt;线程&lt;/font&gt;&lt;/h4&gt;
&lt;p&gt;人们又发现一个问题，cpu切换多个进程的时候，会花费不少的时间，因为切换进程需要切换到内核态，而每次调度需要内核态都需要读取用户态的数据，进程一旦多起来，cpu调度会消耗一大堆资源，因此引入了&lt;font color=red&gt;线程&lt;/font&gt;的概念，线程本身几乎不占有资源，他们共享进程里的资源，内核调度起来不会那么像进程切换那么耗费资源。&lt;/p&gt;
&lt;h4&gt;&lt;font color=#2f8bdc&gt;协程&lt;/font&gt;&lt;/h4&gt;
&lt;p&gt;但是线程还是需要内核去进行调度，切换起来也是需要把用户态的数据写入到内核态，也是需要耗费一定的计算机资源，那可以不可以将切换的调度改成我们自己控制的呢，答案是有的，协程就是把自己的调度算法交给程序（用户态）去进行管理，能以更小的资源去进行并发。&lt;/p&gt;
&lt;h4&gt;&lt;font color=#2f8bdc&gt;goruntine&lt;/font&gt;&lt;/h4&gt;
&lt;p&gt;goroutine就是一个协程例子，可以根据自身调度器进行调度，当某个gooutine调用了time.sleep方法或者channel，mutex阻塞时候，调度器会使其入睡，唤醒另一个goroutine，根本不需要进入到内核态。&lt;/p&gt;
&lt;h2&gt;2.通信&lt;/h2&gt;
&lt;p&gt;goroutine本质上是协程，可以理解为不受内核调度，而受go调度器管理的线程。goroutine之间可以通过channel进行通信，如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;func main() {
    c := make(chan string)
    go func(){
        c &amp;lt;- &quot;hello&quot;
    }()

    go func(){
       word := &amp;lt;- c + &quot; world&quot;
       fmt.Println(word)
    }()
    time.Sleep(1 * time.Second)
}&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;3.安全退出&lt;/h2&gt;
&lt;p&gt;goroutine只有在自身所在函数运行完毕，或者主函数运行完毕才会打断，因而上面的例子需要等待一秒，不然未执行完的goroutine会直接被打断。  如果我们并发的线程数量多了之后，我们不可能在main里面设置一个精确睡眠时间来评估所有的goroutine已经运行完毕然后退出。&lt;br /&gt;
这时候我们可以使用sync.WaitGroup来等待所有运行的goroutine运行结束后，再来退出main函数，主要原理是维护一个goroutine数量的计数器，每运行一个goroutine，计数器会加+1，运行结束后，计数器会-1，然后调用wait方法会一直阻塞，知道计数器为0，也就是当前运行的goroutine数量为0，实例如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;func main() {
    var n sync.WaitGroup
    for i := 0; i &amp;lt; 20; i++ {
        n.Add(1)
        go func(i int, n *sync.WaitGroup) {
            defer n.Done()
            time.Sleep(1 * time.Second)
            fmt.Printf(&quot;goroutine %d is running\n&quot;, i)
        }(i, &amp;amp;n) 
    }   
    n.Wait()
}&lt;/code&gt;&lt;/pre&gt;            </description>
            <pubDate>2019-10-01 09:05:00</pubDate>
            <link>//blog/Go/goroutine.html</link>
            <guid isPermaLink="true">//blog/Go/goroutine.html</guid>
                                               <category>Go</category>
                                    </item>
                <item>
            <title>docker学习系列（五）：使用docker创建集成服务——lnmp</title>
            <description>
            &lt;!--
author: sbb
head: http://pingodata.qiniudn.com/jockchou-avatar.jpg
date: 2018-3-22
title: docker学习系列（五）：使用docker创建集成服务——lnmp
tags: Linux Docker
images: http://pingodata.qiniudn.com/cube2.jpg
category: Docker
status: publish
summary: 使用docker创建继承服务之lnmp，管理集成软件从此更轻松。
--&gt;
&lt;p&gt;在掌握了docker的基本命令之后，我也是想着去用docker做一点实际的配套环境，就拿自己最常用的lnmp环境来做测试。配套环境运行的顺序依次是mysql-&amp;gt;php-&amp;gt;nginx，至于为什么，在下面会解释。&lt;/p&gt;
&lt;h3&gt;1.MySQL&lt;/h3&gt;
&lt;p&gt;之后服务运行的镜像如无特别的提示，都是从官方拉取的镜像，对于小企业以及个人开发者，官方的镜像更为安全，省心省力。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 拉取镜像
$ docker pull mysql
# 运行MySQL
$ docker run --name mysql -d \
        -p 3306:3306 \
        -v /var/lib/mysql/:/var/lib/mysql/ \
        -e MYSQL_ROOT_PASSWORD=yourdbpw \
        MySQL&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;下面依次讲解上面运行各个参数  &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;--name: 指定的运行的容器的名字&lt;br /&gt;
-d: 后台运行该容器&lt;br /&gt;
-p: 宿主机与容器的端口的映射&lt;br /&gt;
-v: 容器挂载到本地的目录映射&lt;br /&gt;
-e: 指定运行容器的环境变量&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;2.PHP&lt;/h3&gt;
&lt;p&gt;拉取官方镜像php-fpm，根据自己需要的php版本去下载，但是官方的镜像有些php常用的包没有包含在内，因此我们需要使用dockerfile去重新构建一下，下面是在Dockerfile里面安装mysqli和pdo两个php扩展包。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM php:7.1-fpm
# Install modules
RUN docker-php-ext-install mysqli &amp;amp;&amp;amp; docker-php-ext-enable mysqli
RUN docker-php-ext-install pdo_mysql
CMD [&quot;php-fpm&quot;]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;运行php-fpm&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run -d -p 9000:9000 \
    --name php-fpm \
    --link mysql \
    -v /data/wwwroot/:/data/wwwroot/ \
    php-fpm&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注意参数当中的--link，这个参数在容器之间的连接十分有用，他会在当前容器的/etc/hosts里面添加一条域名解析，通过该域名可以连接到对应的容器，例如在上述的php-fpm里面，link到mysql，那么在php-fpm里面的php程序可以通过mysql字符串连接到刚刚运行的mysql容器，cat /etc/hosts就可以看到里面的解析记录了。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;172.17.0.2  mysql b41d2569c06d&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;3.Nginx&lt;/h3&gt;
&lt;p&gt;通过以下命令运行nginx，由于nginx需要通过127.0.0.1:9000端口去连接php-fpm来解析php文件，所以需要通过link来连接php-fpm。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run -d -p 80:80  \
    --name nginx \
    --link php-fpm \
    -v /data/wwwroot/:/data/wwwroot/ \
    nginx&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;值得注意的是如果nginx解析文件的时候，如果请求的是静态文件，会直接返回该nginx容器里面的文件到客户端，如果请求的是php文件，他会把这个请求转发到php-fpm，然后php-fpm去本地去找php文件进行解析，也就是php-fpm容器本身的文件。&lt;/p&gt;
&lt;p&gt;依次运行上面的3个服务的启动命令之后就可以搭建我们常见的lnmp了。但是每次运行服务都需要运行上面的命令显得有点麻烦，我们可以使用docker-compose命令去进行集中管理。&lt;/p&gt;
&lt;h3&gt;使用docker-compose&lt;/h3&gt;
&lt;p&gt;只需要创建一个lnmp目录，然后在lnmp目录下创建docker-compose.yml输入下面命令即可管理集成化的环境。&lt;br /&gt;
其实可以通过命令的名字就很容易知道各个指令的含义。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;version: 由于docker-compose是一个发展中的工具，很有可能每个版本的指令都有所不同，因此需要在开头声明docker-compose指令的适用版本。
image: 指服务通过哪个镜像进行运行。
depends_on: 这个指明了软件的依赖与哪个软件，其实也是声明了软件运行的顺序。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code&gt;version: '2'

services:
    mysql:
        image: &quot;mysql&quot;
        ports:
            - &quot;3306:3306&quot;
        volumes:
            - /var/lib/mysql/:/var/lib/mysql/
        environment:
            MYSQL_ROOT_PASSWORD: password

    php-fpm:
        image: &quot;php-fpm&quot;
        depends_on:
            - mysql
        links:
            - mysql
        ports:
            - &quot;9000:9000&quot;
        volumes:
            - /data/wwwroot/:/data/wwwroot/

    nginx:
        image: &quot;nginx&quot;
        depends_on:
            - php-fpm
        links:
            - php-fpm
        volumes:
            - /data/wwwroot/:/data/wwwroot/
        ports:
            - &quot;80:80&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;之后在这个lnmp目录下执行compose相关命令就可以控制。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 运行docker-compose服务
$ docker-compose up -d
# 停止服务
$ docker-compose stop
# 删除该服务相关的容器
$ docker-compose rm
# 运行已存在docker-compose的服务
$ docker-compose start&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;最后，我把自己的调优过的lnmp的docker-compose放到&lt;a href=&quot;https://github.com/sbb520/lnmp_docker&quot;&gt;github&lt;/a&gt;上，有需要可以参考一下。&lt;/p&gt;            </description>
            <pubDate>2019-10-01 09:05:00</pubDate>
            <link>//blog/docker/docker5.html</link>
            <guid isPermaLink="true">//blog/docker/docker5.html</guid>
                                               <category>Docker</category>
                                    </item>
                <item>
            <title>docker学习系列（四）：数据持久化</title>
            <description>
            &lt;!--
author: sbb
head: http://pingodata.qiniudn.com/jockchou-avatar.jpg
date: 2018-3-19
title: docker学习系列（四）：数据持久化
tags: Linux Docker
images: http://pingodata.qiniudn.com/cube2.jpg
category: Docker
status: publish
summary: 学习docker的持久化
--&gt;
&lt;p&gt;需要搞清楚一个概念的是，docker的容器设计理念是可以即开即用，用完可以随意删除，而新建容器是根据镜像进行渲染，容器的修改是不会影响到镜像，但是有时候容器里面运行的产生的数据（如mysql）或者配置项（如nginx的nginx.conf）我们又需要保存起来的，因而我们需要对容器某些修改的数据进行挂载。&lt;/p&gt;
&lt;p&gt;下面介绍三种持久化数据的方式&lt;/p&gt;
&lt;h3&gt;1.挂载磁盘到本地&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;docker run -v 宿主目录:容器挂载的目录 镜像&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这时候docker会自动在对应的目录下进行挂载，值得注意的是，如果容器里面没有宿主机对应的目录，那么容器会自动创建对应的目录。如果没有指定宿主目录，那么会自动在/var/lib/docker/volumes/下进行挂载。&lt;/p&gt;
&lt;h3&gt;2.使用数据容器&lt;/h3&gt;
&lt;p&gt;可以选择创建docker容器，来作为共享数据的容器。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 创建数据容器
docker create -v 宿主目录:容器目录 --name 数据容器名字 基于的环境
# 挂载
docker run --volumes-from 数据容器名字 镜像 
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;3.持久化到镜像&lt;/h3&gt;
&lt;p&gt;适用于镜像里的某些运行环境的修改，如php-fpm里面还需要多安装一个php-pdo之类的东西。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 保存更改并生成为一个新的image文件
$ docker commit -m &quot;mess&quot; 镜像id 镜像名字&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;操作挂载盘&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;# 查看全部volume
docker volume ls
# 删除对应的volume
docker volume rm volumeid&lt;/code&gt;&lt;/pre&gt;            </description>
            <pubDate>2019-10-01 09:05:00</pubDate>
            <link>//blog/docker/docker4.html</link>
            <guid isPermaLink="true">//blog/docker/docker4.html</guid>
                                               <category>Docker</category>
                                    </item>
                <item>
            <title>docker学习系列（三）：docker镜像的分层结构</title>
            <description>
            &lt;!--
author: sbb
head: http://pingodata.qiniudn.com/jockchou-avatar.jpg
date: 2018-3-1
title: docker学习系列（三）：docker镜像的分层结构
tags: Linux Docker
images: http://pingodata.qiniudn.com/cube2.jpg
category: Docker
status: publish
summary: 详解docker镜像与容器间的关联────分层结构
--&gt;
&lt;p&gt;docker里的镜像绝大部分都是在别的镜像的基础上去进行创建的，也就是使用镜像的分层结构。&lt;/p&gt;
&lt;h3&gt;实验&lt;/h3&gt;
&lt;p&gt;比如说使用dockerfile去创建一个最简单的hello镜像。创建好对应的dockerfile之后去进行创建：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM alpine:latest
MAINTAINER sbb
CMD echo &quot;hello world&quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;执行了上面的命令我们可以看到存在着两个镜像，其中hello_world是我刚刚创建好的镜像。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker images
alpine
hello_world&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;docker分层&lt;/h3&gt;
&lt;p&gt;那么为什么会有两个镜像呢？这是由于docker的镜像分层结构所导致的，如下图所示。
&lt;img src=&quot;/blog/img/docker/img1.png&quot; alt=&quot;image&quot; /&gt;&lt;br /&gt;
一个docker镜像由多个&lt;font color=red&gt;可读的镜像层&lt;/font&gt;组成，然后运行的容器会在这个docker的镜像上面多加一层&lt;font color=red&gt;可写的容器层&lt;/font&gt;，任何的对文件的更改都只存在此容器层。因此任何对容器的操作均不会影响到镜像。&lt;/p&gt;
&lt;h3&gt;如何实现&lt;/h3&gt;
&lt;p&gt;至于容器如何获取&lt;font color=red&gt;镜像层文件&lt;/font&gt;而又不影响到是镜像层的呢？docker是这样实现的？
如果需要获取某个文件，那么容器曾会&lt;font color=red&gt;从上到下&lt;/font&gt;去下一层的镜像层去获取文件，如果该层文件不存在，那么就会去下一镜像层去寻找，直到最后一层。
对于用户而言，用户面向的是一个叠加后的文件系统。&lt;br /&gt;
&lt;img src=&quot;/blog/img/docker/img2.jpg&quot; alt=&quot;image&quot; /&gt;   &lt;/p&gt;
&lt;p&gt;而任何对于文件的操作都会记录在容器层，例如说修改文件，容器层会把在镜像层找到的文件拷贝到容器层然后进行修改，删除文件则会在容器层内记录删除文件的记录。&lt;/p&gt;
&lt;h3&gt;综述&lt;/h3&gt;
&lt;p&gt;可能会有人会文为什么要这么去做呢？我觉得有两大好处：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;基本上每个软件都是基于某个镜像去运行的，因此一旦某个底层环境出了问题，就不需要去修改全部基于该镜像的软件的镜像，只需要修改底层环境的镜像。&lt;/li&gt;
&lt;li&gt;这个好处也是最大好处，就是可以共享资源，其他相同环境的软件镜像都共同去享用同一个环境镜像，而不需要每个软件镜像要去创建一个底层环境。
&lt;h3&gt;&lt;/h3&gt;&lt;/li&gt;
&lt;/ol&gt;            </description>
            <pubDate>2019-10-01 09:05:00</pubDate>
            <link>//blog/docker/docker3.html</link>
            <guid isPermaLink="true">//blog/docker/docker3.html</guid>
                                               <category>Docker</category>
                                    </item>
                <item>
            <title>docker学习系列（一）：docker 基础</title>
            <description>
            &lt;!--
author: sbb
head: http://pingodata.qiniudn.com/jockchou-avatar.jpg
date: 2018-3-1
title: docker学习系列（一）：docker 基础
tags: Linux Docker
images: http://pingodata.qiniudn.com/cube2.jpg
category: Docker
status: publish
summary: 初学docker，记录何为docker以及应用场景，以及基本的使用方法。
--&gt;
&lt;h2&gt;一.简介&lt;/h2&gt;
&lt;p&gt;开发当中比较麻烦的问题在于软件配置，每个人的机械以及系统都不尽相同，程序需要运行在系统当中需要配置好相应的系统以及各种依赖的组件，但是很多时候由于各种软件依赖包的版本，系统兼容性问题会导致程序运行出现问题，人们便寻求一种可以解决这种问题的方法。&lt;/p&gt;
&lt;h4&gt;虚拟机&lt;/h4&gt;
&lt;p&gt;而虚拟机技术就是其中的一种解决方法,众所周知，虚拟机技术允许一种操作系统之上运行另一种操作系统，如win系统安装linux的虚拟机，而里面的运行程序却认为自己依旧运行在linux里面，因此用户只需要打包整个自己的运行环境，就可以在不同的系统利用虚拟机技术完美运行程序所需要的系统，而里面的程序更不在话下，且打包好的系统对于运行的系统而言只是一个文件，可以轻松管理。  &lt;/p&gt;
&lt;p&gt;但是虚拟机技术却有一种比较大的问题，那就是用户明明只需要运行某个程序，却需要引入该程序所处的整个系统，不但占用的空间很大，且启动速度也比较慢，毕竟需要启动整个系统。&lt;/p&gt;
&lt;h3&gt;容器技术&lt;/h3&gt;
&lt;p&gt;由于虚拟机存在这些缺点，Linux发展出了另一个虚拟技术：Linux容器，相对于虚拟机，Linux容器不是模仿一个完整的操作系统，而是对进程进行隔离。在这个容器里面，它接触到的资源都是虚拟的，他只需要它本身所需要的组件，相对于虚拟机技术而言，更轻量级，而docker就是对Linux容器的一种封装，提供给我们简单易用的接口，将应用程序以及依赖打包在一个文件里面。&lt;/p&gt;
&lt;h2&gt;二.安装docker&lt;/h2&gt;
&lt;p&gt;我是ubuntu系统，安装docker可以使用官方的快捷安装脚本进行安装。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ wget -qO- https://get.docker.com/ | sh&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;但是我安装起来有点问题，在添加gbp的时候，所以我是安装&lt;a href=&quot;https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-16-04&quot;&gt;教程&lt;/a&gt;一步步安装的。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 添加gbp，但是我按照官方教程执行有点问题，去掉最后一个-符号就可以执行
$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
# 添加APT资源
$ sudo add-apt-repository &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot;
$ sudo apt-get update
# 查看源是否已经生效
$ apt-cache policy docker-ce
# 这时候应该输出类似于这种东西，如果没有这些输出的话，下面的安装就会找不到软件包了
# docker-ce:
#   Installed: (none)
#   Candidate: 17.03.1~ce-0~ubuntu-xenial
#   Version table:
#      17.03.1~ce-0~ubuntu-xenial 500
#         500 https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages
#      17.03.0~ce-0~ubuntu-xenial 500
#         500 https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages

# 最后安装docker
$ sudo apt-get install -y docker-ce
# 安装之后执行以下命令有信息输出即证明成功
$ sudo systemctl status docker
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;之后我们可以通过下载一个镜像来尝试运行hello world。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run ubuntu echo &quot;Hello world&quot;&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;三.使用国内源&lt;/h2&gt;
&lt;p&gt;我们的docker在国内下载镜像并不会很流畅，所以我选择使用&lt;a href=&quot;https://www.docker-cn.com/registry-mirror&quot;&gt;国内官方的景象&lt;/a&gt;。
我直接新建文件：/etc/docker/daemon.json，然后添加如下json，重启docker即可永久选择国内镜像。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
  &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;]
}&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;四.docker的基本概念&lt;/h2&gt;
&lt;h3&gt;1.image（镜像）&lt;/h3&gt;
&lt;p&gt;docker把应用程序以及其依赖，打包在image文件里面，docker容器是通过运行image生成的实例，同一个image文件可以生成多个容器实例。&lt;/p&gt;
&lt;h3&gt;2.container（容器）&lt;/h3&gt;
&lt;p&gt;container是一个docker的运行实例，也叫做容器，本身也是一个文件，可以理解容器实例就是通过渲染运行image镜像之后才产生的。值得注意的是生成容器之后，关闭容器不会删除该容器文件，该容器文件之后停止运行了而已。&lt;/p&gt;
&lt;h2&gt;五.基本命令&lt;/h2&gt;
&lt;p&gt;镜像操作&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 查看当前本地镜像列表
$ docker images
# 查看远程相关镜像镜像
$ docker search 镜像名字
# 拉取镜像到本地
$ docker pull 镜像名字
# 删除镜像（当存在多个名字一样的镜像时候，可以通过指定tag方式来操作，如ubuntu:16.04）
$ docker rmi 镜像名字&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;容器的基本操作&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 创建一个docker容器，返回容器的id
$ docker create 镜像名字
# 运行docker容器
$ docker start 容器id
# 新建容器且运行，也就是上面两步一块执行。
# 值得注意的是如果该镜像在本地不存在，会自动从源那里去拉取
$ docker run 镜像名字
# 停止容器
$ docker stop 容器id
# 查看当前运行的docker容器
$ docker ps
# 查看全部的docker容器
$ docker ps -a
# 删除容器
$ docker rm 容器id&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;新建容器（docker run 镜像）常见可选参数：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;p：指定映射端口，如运行一个nginx服务，那么我可以设置 -p 8080:80来把本地的8080端口映射到容器里的80端口。&lt;/li&gt;
&lt;li&gt;d：容器作为一个守护进程去进行运行，也就是保持后台运行，运行后会返回cotainer id。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;容器与镜像间的操作&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 终端连接到容器
$ docker exec -i -t 容器id bash
# 复制文件到容器里面
$ docker cp index.html 镜像id://usr/share/nginx/html
# 保存更改并生成为一个新的image文件
$ docker commit -m &quot;mess&quot; 镜像id 镜像名字&lt;/code&gt;&lt;/pre&gt;            </description>
            <pubDate>2019-10-01 09:05:00</pubDate>
            <link>//blog/docker/docker1.html</link>
            <guid isPermaLink="true">//blog/docker/docker1.html</guid>
                                               <category>Docker</category>
                                    </item>
                <item>
            <title>docker学习系列（二）：使用Dockerfile创建自己的镜像</title>
            <description>
            &lt;!--
author: sbb
head: http://pingodata.qiniudn.com/jockchou-avatar.jpg
date: 2018-3-1
title: docker学习系列（二）：使用Dockerfile创建自己的镜像
tags: Linux Docker
images: http://pingodata.qiniudn.com/cube2.jpg
category: Docker
status: publish
summary: 使用dockerfile创建自己的镜像。
--&gt;
&lt;p&gt;dockerfile可以允许我们自己创建镜像，通过编写里面的下载软件命令，执行docker build 即可生成镜像文件。&lt;/p&gt;
&lt;h2&gt;初尝dockerfile&lt;/h2&gt;
&lt;p&gt;新建一个目录test，然后进入这个目录，创建一个名为Dockerfile的文件，在里面写入以下内容：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM alpine:latest
MAINTAINER sbb
CMD echo &quot;hello world&quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;然后执行下面命令就会生成docker镜像。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker build -t hello-world .&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;执行docker run hello-world 就会输出hello world了。&lt;br /&gt;
可能会有童鞋会问上面写的是什么，下面会根据命令讲解的。&lt;/p&gt;
&lt;h2&gt;dockerfile命令&lt;/h2&gt;
&lt;p&gt;dockerfile的指令分为两种：构建指令和设置指令。&lt;br /&gt;
构建命令：用于构建镜像的时候执行的，不会在该镜像上的容器里执行。  设置命令：用于设image的属性，将会在运行的容器里执行。&lt;/p&gt;
&lt;h4&gt;FROM&lt;/h4&gt;
&lt;p&gt;指定基础image，其实大部分镜像都是基于另一个镜像的基础上去进行修改的，比如说我这个apt-get安装的nginx是基于ubuntu的（上面例子里的alpine是docker提供的最小镜像），这个命令需要放在最前面。&lt;br /&gt;
命令格式如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM 镜像名字:版本&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;MAINTAINER&lt;/h4&gt;
&lt;p&gt;构建命令，用于指定创建者是谁。&lt;/p&gt;
&lt;h4&gt;RUN&lt;/h4&gt;
&lt;p&gt;构建命令，RUN可以运行全部被基础镜像支持的命令,常用于搭建环境。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;RUN apt-get update
RUN apt-get install -y nginx&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;CMD&lt;/h4&gt;
&lt;p&gt;设置命令，在docker容器启动时候执行的命令，多个CMD命令存在的话只会运行最后一个CMD命令，因此只需要写一个CMD命令即可。CMD命令有三种执行方式&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 方式一，运行一个可执行文件，并提供参数(like an exec, this is the preferred form)
CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] 
# 方式二，利用”/bin/sh -c”去执行， (as a shell)
CMD command param1 param2
# 方式三，作为ENTRYPOINT的默认参数
CMD [&quot;param1&quot;, &quot;param2&quot;]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在使用docker run imagename  command新建并启动容器的时候，command会替换dockerfile里的CMD命令，如上面我们创建的docker镜像，如果后面输入了hello docker，则不会输出hello world了，本来dockerfile里面指定了输出hello world。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ docker run hello_docker echo &quot;hello docker&quot;
hello docker
$ docker run hello_docker                    
hello world&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;ENTRYPOINT&lt;/h4&gt;
&lt;p&gt;设置命令，在docker容器启动时候执行的命令，一个dockerfile只能有一个ENTRYPOINT命令，有两种执行方式：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] 
ENTRYPOINT command param1 param2 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;和CMD命令很相似，但是区别在于docker run imagename command的时候，command部分是作为参数传给ENTRYPOINT的。&lt;/p&gt;
&lt;h4&gt;USER&lt;/h4&gt;
&lt;p&gt;指定允许启动的用户，默认是root&lt;/p&gt;
&lt;h4&gt;EXPOSE&lt;/h4&gt;
&lt;p&gt;指定容器要暴露的端口，常用于一些需要通信的应用，如nginx，就会在dockerfile指定暴露80端口，或者在docker run时指定 --expose=1234，这两种方式作用相同，但是--expose可以接受区间范围的端口作为参数。&lt;/p&gt;
&lt;p&gt;注意expose暴露的是容器的端口，如果外面主机需要通过端口连接到这个服务，需要进行一个映射，把容器的端口映射到主机的端口。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker run -p 本地端口:暴露端口 镜像&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;最后附上一个简单创建nginx的dockerfile&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM ubuntu
MAINTAINER sbb
RUN apt-get update
RUN apt-get install -y nginx
ENTRYPOINT [&quot;/usr/sbin/nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;]
EXPOSE 80&lt;/code&gt;&lt;/pre&gt;            </description>
            <pubDate>2019-10-01 09:05:00</pubDate>
            <link>//blog/docker/docker2.html</link>
            <guid isPermaLink="true">//blog/docker/docker2.html</guid>
                                               <category>Docker</category>
                                    </item>
                <item>
            <title>搭建laravel到nginx</title>
            <description>
            &lt;!--
author: sbb
head: http://pingodata.qiniudn.com/jockchou-avatar.jpg
date: 2018-2-27
title: 搭建laravel到nginx
tags: PHP laravel
images: http://pingodata.qiniudn.com/cube2.jpg
category: PHP
status: publish
summary: laravel在nginx上的配置有点麻烦，我费了不少的功夫才弄好，下面分享一下搭建的过程。
--&gt;
&lt;h2&gt;一.laravel的安装&lt;/h2&gt;
&lt;p&gt;搭建的第一步当然是安装好laravel，这里推介composer安装，由于国内的问题，极其推介使用国内的镜像去搭建，我在终端里本已经设置好常规的https和http之类的翻墙代理，最后还是不能使用常规的方式下载，最后还是老老实实用国内镜像下载。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 设置全局的composer下载镜像为国内镜像
composer config -g repo.packagist composer https://packagist.phpcomposer.com
# 下载laravel
composer create-project --prefer-dist laravel/laravel myproject &quot;5.5.*&quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;期间可能会遇到一些php函数执行失败（由于php会限制一些涉及到安全问题的函数，如exec，需要在php.ini里面去进行设置，然后重启php-fpm即可）&lt;/p&gt;
&lt;h1&gt;二. 部署到nginx&lt;/h1&gt;
&lt;p&gt;根据&lt;a href=&quot;https://d.laravel-china.org/docs/5.5/deployment#nginx&quot;&gt;官方文档&lt;/a&gt;，我直接加入对应的规则，具体的根据自己服务器去进行跳转，需要注意的是映射的网站是根目录public。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;server {
    listen 80;
    server_name example.com;
    root /example.com/public;

    # 注意这个error_log，有些错误可能页面不会展示出来，但是可以通过nginx的error_log查询出来
    error_log /home/wwwroot/error.log;  

    add_header X-Frame-Options &quot;SAMEORIGIN&quot;;
    add_header X-XSS-Protection &quot;1; mode=block&quot;;
    add_header X-Content-Type-Options &quot;nosniff&quot;;

    index index.html index.htm index.php;

    charset utf-8;

    location / {
        try_files $uri $uri/ /index.php?$query_string;
    }

    location = /favicon.ico { access_log off; log_not_found off; }
    location = /robots.txt  { access_log off; log_not_found off; }

    error_page 404 /index.php;

    location ~ \.php$ {
        fastcgi_split_path_info ^(.+\.php)(/.+)$;
        fastcgi_pass unix:/var/run/php/php7.1-fpm.sock;
        fastcgi_index index.php;
        include fastcgi_params;
    }

    location ~ /\.(?!well-known).* {
        deny all;
    }
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;service nginx restart&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;设置好对应目录的权限，如无意外的话一般这个时候访问对应的域名应该是ok的了。&lt;/p&gt;
&lt;h1&gt;三.遇到的坑&lt;/h1&gt;
&lt;p&gt;我在配置好对应的环境之后，访问对应的域名，只返回一个500的错误提示，且这个提示不是laravel返回的，看得我有点懵，这时候可以帮助调试的有三个东西。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;设置laravel为调试模式，在.env和app.config里面设置即可。&lt;/li&gt;
&lt;li&gt;设置php.ini里面的display_errors改为On。&lt;/li&gt;
&lt;li&gt;查看nginx的error.log。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;最后我是通过查看nginx的error.log来发现问题的所在的，原因是laravel用到open_basedir这个函数，而这个函数在我的nginx的fastcgi_param里面是不允许访问除了当前目录以外的其他目录，于是我把这个限制给去掉。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#fastcgi_param PHP_ADMIN_VALUE &quot;open_basedir=$document_root/:/tmp/:/proc/&quot;;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;另外在php.ini也有这样的限制，把这个限制注释掉即可，然后重启服务即可。&lt;/p&gt;            </description>
            <pubDate>2019-10-01 09:05:00</pubDate>
            <link>//blog/PHP/laravel/nginx-conf.html</link>
            <guid isPermaLink="true">//blog/PHP/laravel/nginx-conf.html</guid>
                                               <category>PHP</category>
                                    </item>
                <item>
            <title>在ubuntu翻墙</title>
            <description>
            &lt;!--
author: sbb
head: http://pingodata.qiniudn.com/jockchou-avatar.jpg
date: 2018-02-13
title: 在ubuntu翻墙
tags: Linux
images: http://pingodata.qiniudn.com/cube2.jpg
category: Linux
status: publish
summary: 本文章记录自己在ubuntu翻墙的实现方法...
--&gt;
&lt;h2&gt;一. 安装ssr客户端&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;wget http://www.djangoz.com/ssr
sudo mv ssr /usr/local/bin
sudo chmod 766 /usr/local/bin/ssr
ssr install
ssr config&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;具体的操作方式其实可以打开第一步下载的脚本看看的，开头有注释&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;二. 全局代理（最简单方法）&lt;/h2&gt;
&lt;p&gt;直接打开ubuntu的网络设置去进行设置。&lt;br /&gt;
setting-&amp;gt;network-&amp;gt;network proxy&lt;br /&gt;
&lt;img src=&quot;/blog/img/SSR/ubuntu/1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h2&gt;三. chrome翻墙&lt;/h2&gt;
&lt;p&gt;下载SwitchySharp，添加到chrome扩展中，然后进行设置。&lt;br /&gt;
首先设置 Proxy Profiles设置里面的manual config里的SOCKS Host，根据自己的ssr去进行设置。&lt;br /&gt;
&lt;img src=&quot;/blog/img/SSR/ubuntu/2.png&quot; alt=&quot;&quot; /&gt;  &lt;/p&gt;
&lt;p&gt;如果自己不需要浏览器全局代理，那么设置switch rules，根据自己的需要代理的网站去进行设置，其他不需要翻墙的网站则不需要代理，例如说我经常用谷歌和百度，就仅仅设置谷歌&lt;br /&gt;
&lt;img src=&quot;/blog/img/SSR/ubuntu/3.png&quot; alt=&quot;&quot; /&gt;  &lt;/p&gt;
&lt;p&gt;使用的时候我一般使用Auto Switch Mode&lt;br /&gt;
&lt;img src=&quot;/blog/img/SSR/ubuntu/4.png&quot; alt=&quot;&quot; /&gt;  &lt;/p&gt;
&lt;p&gt;如果遇到一些不常用的外国网站可以直接设置回自己浏览器全局代理模式。
&lt;img src=&quot;/blog/img/SSR/ubuntu/5.png&quot; alt=&quot;&quot; /&gt;  &lt;/p&gt;
&lt;h2&gt;四. 终端翻墙&lt;/h2&gt;
&lt;p&gt;使用privoxy进行代理，在配置文件（/etc/privoxy/config）进行如下设置&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;forward-socks5 / 127.0.0.1:1080 .
# local network do not use proxy
forward         192.168.*.*/    .
forward         10.*.*.*/       .
forward         127.*.*.*/      .&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;根本配置文件找到代理端口，搜索listen-address 看到端口是8118&lt;br /&gt;
然后重启服务，在终端输入以下命令即可&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export http_proxy=&quot;http://127.0.0.1:8181&quot;
export https_proxy=$http_proxy
export ftp_proxy=$http_proxy
export rsync_proxy=$http_proxy
export no_proxy=&quot;localhost,127.0.0.1&quot;&lt;/code&gt;&lt;/pre&gt;            </description>
            <pubDate>2019-10-01 09:05:00</pubDate>
            <link>//blog/SSR/ubuntu.html</link>
            <guid isPermaLink="true">//blog/SSR/ubuntu.html</guid>
                                               <category>Linux</category>
                                    </item>
                <item>
            <title>Go的socket服务</title>
            <description>
            &lt;!--
author: sbb
head: http://pingodata.qiniudn.com/jockchou-avatar.jpg
date: 2018-1-22
title: Go的socket服务 
tags: Go
images: http://pingodata.qiniudn.com/cube2.jpg
category: Go
status: publish
summary: 最近研究了Go的socket服务，简单地写了一个cs模型。
--&gt;
&lt;h2&gt;一. server&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;package main

import (
    &quot;fmt&quot;
    &quot;net&quot;
    &quot;os&quot;
    &quot;time&quot;
)

func main() {
    // 设置TCP地址
    service := &quot;127.0.0.1:51000&quot;
    tcpAddr, err := net.ResolveTCPAddr(&quot;tcp4&quot;, service)
    checkError(err)
    // 设置监听
    listener, err := net.ListenTCP(&quot;tcp&quot;, tcpAddr)
    checkError(err)
    // 接受信息
    for {
        conn, err := listener.Accept()
        if err != nil {
            continue
        }
        // go handleClient(conn)
        handleClient(conn)
    }
}

func handleClient(conn net.Conn) {
    // 设置过期时间，过了时间断开连接
    conn.SetReadDeadline(time.Now().Add(2 * time.Minute))
    go getMess(conn)
    go sendMess(conn)
}

func sendMess(conn net.Conn) {
    for {
        var s1 string
        fmt.Scan(&amp;amp;s1)
        fmt.Printf(&quot;我说：&quot;)
        fmt.Println(s1)
        conn.Write([]byte(s1))
    }
}

func getMess(conn net.Conn) {
    data := make([]byte, 128)
    for {
        read_len, err := conn.Read(data)
        checkError(err)
        if read_len == 0 {
            continue
        }
        fmt.Printf(&quot;对面说：&quot;)
        fmt.Println(string(data))
        data = make([]byte, 128)
    }
}

func checkError(err error) {
    if err != nil {
        fmt.Fprintf(os.Stderr, &quot;Fatal error: %s&quot;, err.Error())
        os.Exit(1)
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;二. client&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;package main

import (
    &quot;fmt&quot;
    &quot;net&quot;
    &quot;os&quot;
)

func main() {
    // 设置TCP地址
    tcpAddr, err := net.ResolveTCPAddr(&quot;tcp4&quot;, &quot;127.0.0.1:51000&quot;)
    checkError(err)
    // 连接远程服务器
    conn, err := net.DialTCP(&quot;tcp&quot;, nil, tcpAddr)
    checkError(err)
    _, err = conn.Write([]byte(&quot;hi&quot;))
    checkError(err)

    go sendMess(conn)
    getMess(conn)
}

func getMess(conn net.Conn) {
    data := make([]byte, 128)
    for {
        _, err := conn.Read(data)
        checkError(err)
        fmt.Printf(&quot;对面：&quot;)
        fmt.Println(string(data))
        data = make([]byte, 128)
    }
}

func sendMess(conn net.Conn) {
    for {
        var s1 string
        fmt.Scan(&amp;amp;s1)
        conn.Write([]byte(s1))
        fmt.Printf(&quot;我说：&quot;)
        fmt.Println(s1)
    }
}
func checkError(err error) {
    if err != nil {
        fmt.Fprintf(os.Stderr, &quot;Fatal error: %s&quot;, err.Error())
        os.Exit(-1)
    }
}
&lt;/code&gt;&lt;/pre&gt;            </description>
            <pubDate>2019-10-01 09:05:00</pubDate>
            <link>//blog/Go/socket.html</link>
            <guid isPermaLink="true">//blog/Go/socket.html</guid>
                                               <category>Go</category>
                                    </item>
                <item>
            <title>聚集索引与非聚集索引的总结</title>
            <description>
            &lt;!--
author: sbb
head: http://pingodata.qiniudn.com/jockchou-avatar.jpg
date: 2018-1-22
title: 聚集索引与非聚集索引的总结 
tags: SQL MySQL
images: http://pingodata.qiniudn.com/cube2.jpg
category: SQL
status: publish
summary: 最近研究了SQL的聚集索引以及非聚集索引使用以及其中要点，发现其中有不少技巧以及要点，现总结一下。
--&gt;
&lt;h2&gt;一.索引简介&lt;/h2&gt;
&lt;p&gt;众所周知，索引是关系型数据库中给数据库表中一列或多列的值排序后的存储结构，SQL的主流索引结构有B+树以及Hash结构，聚集索引以及非聚集索引用的是B+树索引。这篇文章会总结SQL Server以及MySQL的InnoDB和MyISAM两种SQL的索引。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;SQL Sever索引类型有：唯一索引，主键索引，聚集索引，非聚集索引。&lt;br&gt;
MySQL 索引类型有：唯一索引，主键（聚集）索引，非聚集索引，全文索引。&lt;br&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;二.聚集索引&lt;/h2&gt;
&lt;p&gt;聚集（clustered）索引，也叫聚簇索引。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;定义：数据行的物理顺序与列值（一般是主键的那一列）的逻辑顺序相同，一个表中只能拥有一个聚集索引。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;单单从定义来看是不是显得有点抽象，打个比方，一个表就像是我们以前用的新华字典，聚集索引就像是拼音目录，而每个字存放的页码就是我们的数据物理地址，我们如果要查询一个“哇”字，我们只需要查询“哇”字对应在新华字典拼音目录对应的页码，就可以查询到对应的“哇”字所在的位置，而拼音目录对应的A-Z的字顺序，和新华字典实际存储的字的顺序A-Z也是一样的，如果我们中文新出了一个字，拼音开头第一个是B，那么他插入的时候也要按照拼音目录顺序插入到A字的后面，现在用一个简单的示意图来大概说明一下在数据库中的样子：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;地址&lt;/th&gt;
&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;username&lt;/th&gt;
&lt;th&gt;score&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0x01&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;小明&lt;/td&gt;
&lt;td&gt;90&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x02&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;小红&lt;/td&gt;
&lt;td&gt;80&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x03&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;小华&lt;/td&gt;
&lt;td&gt;92&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;..&lt;/td&gt;
&lt;td&gt;..&lt;/td&gt;
&lt;td&gt;..&lt;/td&gt;
&lt;td&gt;..&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0xff&lt;/td&gt;
&lt;td&gt;256&lt;/td&gt;
&lt;td&gt;小英&lt;/td&gt;
&lt;td&gt;70&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;注：第一列的地址表示该行数据在磁盘中的物理地址，后面三列才是我们SQL里面用的表里的列，其中id是主键，建立了聚集索引。&lt;br&gt;&lt;/p&gt;
&lt;p&gt;结合上面的表格就可以理解这句话了吧：数据行的物理顺序与列值的&lt;strong&gt;顺序相同&lt;/strong&gt;，如果我们查询id比较靠后的数据，那么这行数据的地址在磁盘中的物理地址也会比较靠后。而且由于物理排列方式与聚集索引的顺序相同，所以也就只能建立一个聚集索引了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/SQL/index/clustered_index_axion.png&quot; alt=&quot;聚集索引示意图&quot; /&gt;&lt;br&gt;
&lt;strong&gt;聚集索引实际存放的示意图&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;从上图可以看出聚集索引的好处了，索引的叶子节点就是对应的数据节点（MySQL的MyISAM除外，此存储引擎的聚集索引和非聚集索引只多了个唯一约束，其他没什么区别），可以直接获取到对应的全部列的数据，而非聚集索引在索引没有覆盖到对应的列的时候需要进行二次查询，后面会详细讲。因此在查询方面，聚集索引的速度往往会更占优势。&lt;/p&gt;
&lt;h3&gt;创建聚集索引&lt;/h3&gt;
&lt;p&gt;如果不创建索引，系统会自动创建一个隐含列作为表的聚集索引。&lt;/p&gt;
&lt;p&gt;1.创建表的时候指定主键（注意：SQL Sever默认主键为聚集索引，也可以指定为非聚集索引，而MySQL里主键就是聚集索引）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;create table t1(
    id int primary key,
    name nvarchar(255)
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;2.创建表后添加聚集索引&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;SQL Server&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;create clustered index clustered_index on table_name(colum_name)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;MySQL&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;alter table table_name add primary key(colum_name)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;值得注意的是，最好还是在创建表的时候添加聚集索引，由于聚集索引的物理顺序上的特殊性，因此如果再在上面创建索引的时候会根据索引列的排序移动全部数据行上面的顺序，会非常地耗费时间以及性能。&lt;/p&gt;
&lt;h2&gt;三.非聚集索引&lt;/h2&gt;
&lt;p&gt;非聚集（unclustered）索引。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;定义：该索引中索引的逻辑顺序与磁盘上行的物理存储顺序不同，一个表中可以拥有多个非聚集索引。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;其实按照定义，除了聚集索引以外的索引都是非聚集索引，只是人们想细分一下非聚集索引，分成普通索引，唯一索引，全文索引。如果非要把非聚集索引类比成现实生活中的东西，那么非聚集索引就像新华字典的偏旁字典，他结构顺序与实际存放顺序不一定一致。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/SQL/index/unclustered_index_axion.png&quot; alt=&quot;非聚集索引示意图&quot; /&gt;&lt;br&gt;
&lt;strong&gt;非聚集索引实际存放的示意图&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;聚合索引的二次查询问题&lt;/h3&gt;
&lt;p&gt;非聚集索引叶节点仍然是索引节点，只是有一个指针指向对应的数据块，此如果使用非聚集索引查询，而查询列中包含了其他该索引没有覆盖的列，那么他还要进行第二次的查询，查询节点上对应的数据行的数据。&lt;/p&gt;
&lt;p&gt;如有以下表t1：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;username&lt;/th&gt;
&lt;th&gt;score&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;小明&lt;/td&gt;
&lt;td&gt;90&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;小红&lt;/td&gt;
&lt;td&gt;80&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;小华&lt;/td&gt;
&lt;td&gt;92&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;..&lt;/td&gt;
&lt;td&gt;..&lt;/td&gt;
&lt;td&gt;..&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;256&lt;/td&gt;
&lt;td&gt;小英&lt;/td&gt;
&lt;td&gt;70&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;以及聚集索引clustered index(id), 非聚集索引index(username)。&lt;/p&gt;
&lt;p&gt;使用以下语句进行查询，不需要进行二次查询，直接就可以从非聚集索引的节点里面就可以获取到查询列的数据。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select id, username from t1 where username = '小明'
select username from t1 where username = '小明'&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;但是使用以下语句进行查询，就需要二次的查询去获取原数据行的score：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select username, score from t1 where username = '小明'&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在SQL Server里面查询效率如下所示，Index Seek就是索引所花费的时间，Key Lookup就是二次查询所花费的时间。可以看的出二次查询所花费的查询开销占比很大，达到50%。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/SQL/index/unclusted_select.png&quot; alt=&quot;查询效率&quot; /&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;在SQL Server里面会对查询自动优化，选择适合的索引，因此如果在数据量不大的情况下，SQL Server很有可能不会使用非聚集索引进行查询，而是使用聚集索引进行查询，即便需要扫描整个聚集索引，效率也比使用非聚集索引效率要高。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/SQL/index/unclusted_select2.png&quot; alt=&quot;查询效率&quot; /&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;本人试过在含有30w行表上建立非聚集索引，查询非聚集索引覆盖以外的列就会变成聚集索引的全索引扫描（index scan）查询来避免二次查询，而在另外一张200w行表才会用到非聚集索引seek对应的列再进行kek lookup，有关于SQL Server的有Index seek，index scan, table scan，key LookUp这几个概念，可以查看这个&lt;a href=&quot;http://www.cnblogs.com/xwdreamer/archive/2012/07/06/2579504.html&quot;&gt;blog&lt;/a&gt;，描写比较详细。&lt;/p&gt;
&lt;p&gt;但在MySQL里面就算表里数据量少且查询了非键列，也不会使用聚集索引去全索引扫描，但如果强制使用聚集索引去查询，性能反而比非聚集索引查询要差，这就是两种SQL的不同之处。&lt;/p&gt;
&lt;p&gt;还有一点要注意的是非聚集索引其实叶子节点除了会存储索引覆盖列的数据，也会存放聚集索引所覆盖的列数据。&lt;/p&gt;
&lt;h3&gt;如何解决非聚集索引的二次查询问题&lt;/h3&gt;
&lt;h4&gt;复合索引（覆盖索引）&lt;/h4&gt;
&lt;p&gt;建立两列以上的索引，即可查询复合索引里的列的数据而不需要进行回表二次查询，如index(col1, col2)，执行下面的语句&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select col1, col2 from t1 where col1 = '213';&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;要注意使用复合索引需要满足最左侧索引的原则，也就是查询的时候如果where条件里面没有最左边的一到多列，索引就不会起作用。&lt;/p&gt;
&lt;p&gt;在SQL Server中还有include的用法，可以把非聚集索引里包含的列包含进来，而不一定需要建立复合索引。&lt;/p&gt;
&lt;h2&gt;四.总结与使用心得&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;使用聚集索引的查询效率要比非聚集索引的效率要高，但是如果需要频繁去改变聚集索引的值，写入性能并不高，因为需要移动对应数据的物理位置。&lt;/li&gt;
&lt;li&gt;非聚集索引在查询的时候可以的话就避免二次查询，这样性能会大幅提升。&lt;/li&gt;
&lt;li&gt;不是所有的表都适合建立索引，只有数据量大表才适合建立索引，且建立在选择性高的列上面性能会更好。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;参考资料：&lt;br&gt;
[1]：&lt;a href=&quot;https://blogs.msdn.microsoft.com/apgcdsd/2012/08/01/sql-serverscan-seek/&quot;&gt;微软技术支持官方博客&lt;/a&gt;&lt;br&gt;
[2]：&lt;a href=&quot;https://www.cnblogs.com/aspnethot/articles/1504082.html&quot;&gt;聚集索引和非聚集索引（整理）&lt;/a&gt;&lt;/p&gt;            </description>
            <pubDate>2019-10-01 09:05:00</pubDate>
            <link>//blog/SQL/index.html</link>
            <guid isPermaLink="true">//blog/SQL/index.html</guid>
                                               <category>SQL</category>
                                    </item>
                <item>
            <title>MySQL复制以及调优</title>
            <description>
            &lt;!--
author: sbb
head: http://pingodata.qiniudn.com/jockchou-avatar.jpg
date: 2018-1-22
title: MySQL复制以及调优 
tags: MySQL
images: http://pingodata.qiniudn.com/cube2.jpg
category: SQL
status: publish
summary: 简述MySQL复制，以及基本的调优。
--&gt;
&lt;h2&gt;一.  简介&lt;/h2&gt;
&lt;p&gt;MySQL自带复制方案，带来好处有：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;数据备份。&lt;br&gt;
负载均衡。&lt;br&gt;
分布式数据。&lt;br&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;概念介绍：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;主机（master）：被复制的数据库。&lt;br&gt;
从机（slave）：复制主机数据的数据库。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;复制步骤：&lt;br /&gt;
(1). master记录更改的明细，存入到二进制日志（binary log）。&lt;br /&gt;
(2). master发送同步消息给slave。&lt;br /&gt;
(3). slave收到消息后，将master的二进制日志复制到本地的中继日志（relay log）。&lt;br /&gt;
(4). slave重现中继日志中的消息，从而改变数据库的数据。  &lt;/p&gt;
&lt;p&gt;下面放一张经典的图片来说明这一过程：
&lt;img src=&quot;/blog/img/SQL/replication/replication-1.png&quot; alt=&quot;复制原理图&quot; /&gt;&lt;/p&gt;
&lt;h2&gt;二.  实现复制&lt;/h2&gt;
&lt;p&gt;实现复制有以下步骤：  &lt;/p&gt;
&lt;h4&gt;1.设置MySQL主库的二进制日志以及server-id&lt;/h4&gt;
&lt;p&gt;MySQL配置文件一般存放在/etc/my.cnf&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 在[mysqld]下面添加配置选项
[mysqld]
server-id=1
log-bin=mysql-bin.log&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;server-id是数据库在整个数据库集群中的唯一标示，必须保持唯一。&lt;br /&gt;
重启MySQL。&lt;br /&gt;
&lt;code&gt;注：如果MySQL配置文件中已经配置过此文件，则可以跳过此步。&lt;/code&gt; &lt;/p&gt;
&lt;h4&gt;2.新建复制账号&lt;/h4&gt;
&lt;p&gt;在主库里面新建用于从库复制主库数据的账号，并授予复制权限。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO user_name@'host' IDENTIFIED BY 'password';&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;3.设置MySQL主库server-id&lt;/h4&gt;
&lt;p&gt;和第二步配置一样，要注意的地方有两点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如果不需要从库作为别的从库的主库的话，则不需要配置二进制日志。&lt;/li&gt;
&lt;li&gt;很多时候复制并不需要复制主库的全部数据库（特别是mysql的信息配置库）。因此可以配置replicate_do_db来指定复制的数据库&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;4.从库初始化主库的数据&lt;/h4&gt;
&lt;p&gt;如果数据量不算大的情况下，可以使用mysqldump工具导出主库数据，然后导入到从库里面。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysqldump --single-transaction --triggers --master-data databasename &amp;gt; data.sql&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果数据量大的情况下应该使用Xtrabackup去进行数据库的导出，此处不做介绍。&lt;br /&gt;
可能会有同学问，为什么不直接使用二进制日志进行初始化呢？  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如果我们主库运行了比较长的一段时间，并不太适合使用从库根据二进制日志进行复制数据，直接使用二进制日志去初始化从库会比较耗费时间和性能。&lt;/li&gt;
&lt;li&gt;更多的情况下，主库的二进制日志的配置项没有打开，因此也就不存在以前操作的二进制日志。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;5.开启复制&lt;/h4&gt;
&lt;p&gt;从库执行下面命令&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysql&amp;gt; CHANGE MASTER TO MASTER_HOST='host',
-&amp;gt; MASTER_USER='user',
-&amp;gt; MASTER_PASSWORD='password',
-&amp;gt; MASTER_LOG_FILE='mysql-bin.000001',
-&amp;gt; MASTER_LOG_POS=0;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注意最后的两个命令：MASTER_LOG_FILE和MASTER_LOG_POS，表示从库的从哪个二进制文件开始读取，偏移量从那里开始，这两个参数可以从我们导入的SQL里面找到。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/blog/img/SQL/replication/replication-2.png&quot; alt=&quot;导入注意&quot; /&gt;  &lt;/p&gt;
&lt;p&gt;开启复制&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;start slave;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这时候就完成了复制，在主库更新一个数据或者新增数据在从库都可以查询到结果。&lt;br /&gt;
&lt;img src=&quot;/blog/img/SQL/replication/replication-4.png&quot; alt=&quot;查看复制&quot; /&gt;&lt;br /&gt;
在主库上也可以查询的到复制线程的状态。&lt;br /&gt;
&lt;img src=&quot;/blog/img/SQL/replication/replication-3.png&quot; alt=&quot;线程状态&quot; /&gt;  &lt;/p&gt;
&lt;h2&gt;三. 复制的日志格式&lt;/h2&gt;
&lt;p&gt;MySQL复制的日志格式有三种，根据主库存放数据的方式不同有以下三种： &lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;复制方式&lt;/th&gt;
&lt;th&gt;特点&lt;/th&gt;
&lt;th&gt;优点&lt;/th&gt;
&lt;th&gt;缺点&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;row&lt;/td&gt;
&lt;td&gt;基于行的格式复制，记录需要修改的每行的数据信息。 如果一个SQL修改了2w行的数据，那么就会记录2w行的日志格式&lt;/td&gt;
&lt;td&gt;保证了数据的强一致性，且由于记录的是执行后的结果，在从库上执行还原也会比较快&lt;/td&gt;
&lt;td&gt;日志记录数量很多，主从之间的传输需要更多的时间。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;statement&lt;/td&gt;
&lt;td&gt;基于段的日志格式复制，也就是记录下更改的SQL记录，而不是更改的行的记录。&lt;/td&gt;
&lt;td&gt;日志记录量最小。&lt;/td&gt;
&lt;td&gt;对于一些输出结果不确定的函数，在从库上执行一遍很可能会出现问题，如uuid，从库根据日志还原主库数据的时候需要执行一遍SQL，时间相对较慢。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mixed&lt;/td&gt;
&lt;td&gt;混合上面两种日志格式记录记录日志，至于什么时候使用哪种日志方式由MySQL本身决定。&lt;/td&gt;
&lt;td&gt;可以平衡上面两种日志格式的优缺点。&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;mysql5.7以前默认使用statement格式。&lt;br /&gt;
设置方式，可以在配置文件设置（首选）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;binlog_format=ROW&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;或临时设置全局变量（当前mysql连接有效）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;查看日志格式
mysql &amp;gt; show variables like 'binlog_format';

设置日志格式
mysql &amp;gt; set binlog_format='row';&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;由于两个主从服务器一般都会放在同一个机房里面，两者之间同步的速度会会比较快，为保证强一致性，应该首选行的日志格式记录（row），保证传输素速度可以选择混合方式（mixed）。&lt;br /&gt;
而行的日志格式有下面三种记录方式：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;记录方式&lt;/th&gt;
&lt;th&gt;特点&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;minimal&lt;/td&gt;
&lt;td&gt;只记录被修改列的数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;full&lt;/td&gt;
&lt;td&gt;记录被修改的行的全部列的数据&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;noblob&lt;/td&gt;
&lt;td&gt;特点同上，只是如果没有修改blob和text类型的列的情况下，不会记录这些列的数据（也就是大数据列）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;mysql默认是full，最好修改成minimal。  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;binlog_row_image=minimal&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;四. 主从复制延迟&lt;/h2&gt;
&lt;p&gt;由于主库和从库之间不在同一个主机上，数据同步之间不可以避免地具有延迟，解决的方法有添加缓存，业务层的跳转等待，如果非得从数据库层面去减缓延迟问题，可以从复制时候的三大步骤（主库产生日志，主从传输日志，从库还原日志内容）入手：&lt;br /&gt;
1.主库写入到日志的速度&lt;br /&gt;
控制主库的事务大小，分割大事务为多个小事务。&lt;br /&gt;
如插入20w的数据，改成插入多次5000行（可以利用分页的思路）&lt;/p&gt;
&lt;p&gt;2.二进制日志在主从之间传输时间
主从之间尽量在同一个机房或地域。&lt;br /&gt;
日志格式改用MIXED，且设置行的日志格式未minimal，原理详见上面的日志格式介绍。  &lt;/p&gt;
&lt;p&gt;3.减少从库还原日志的时间&lt;br /&gt;
在MySQL5.7版本后可以利用逻辑时钟方式分配SQL多线程。&lt;br /&gt;
设置逻辑时钟：slave_parallel_type=‘logical_clock’;&lt;br /&gt;
设置复制线程个数：slave_parallel_workers=4;  &lt;/p&gt;
&lt;h2&gt;五.  需要注意的地方&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;重启MySQL最好切换未MySQL用户再进行操作，不然文件启动后会有权限问题。&lt;/li&gt;
&lt;li&gt;搭建好MySQL的环境后就设置好配置里的log-bin选项，这样以后如果数据库需要从库的复制，就不需要重启数据库，打断业务的进行。&lt;/li&gt;
&lt;li&gt;需要打开主库的防火墙的对应的mysql端口。 &lt;/li&gt;
&lt;li&gt;由于从库同步主库的方式，监听主库发送的信息，而不是轮询，因此如果出现通信出现了故障，重新连接后如果主库没有进行数据更改的操作，从库不会同步数据，因此可以通过插入空事务的方式同步数据。
&lt;br&gt;
&lt;br&gt;&lt;/li&gt;
&lt;/ol&gt;            </description>
            <pubDate>2019-10-01 09:05:00</pubDate>
            <link>//blog/SQL/replication.html</link>
            <guid isPermaLink="true">//blog/SQL/replication.html</guid>
                                               <category>SQL</category>
                                    </item>
                <item>
            <title>remi源-为你的php装上主流的扩展库</title>
            <description>
            &lt;!--
author: sbb
head: http://pingodata.qiniudn.com/jockchou-avatar.jpg
date: 2017-12-5
title: remi源-为你的php装上主流的扩展库
tags: Linux centos
images: http://pingodata.qiniudn.com/cube2.jpg
category: Linux
status: publish
summary: 目前最最主流的php版本是5.6或php7，往往我们想为我们的当前版本的php装上合适的扩展库，但使用默认的yum源安装都会出现conflict不兼容提示，为了解决这个问题，我将会介绍如何用上主流的扩展库。
--&gt;
&lt;h2&gt;一.简介&lt;/h2&gt;
&lt;p&gt;目前最最主流的php版本是5.6或php7，往往我们想为我们的当前版本的php装上合适的扩展库，但使用默认的yum源安装都会出现conflict不兼容提示（因为默认的yum源为了稳定性所引用的软件版本都是非常的低），为了解决这个问题，我将会介绍如何用上主流的remi软件源，拥有主流版本的库且稳定。主要的配置流程如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;检测你当前linux的版本&lt;/li&gt;
&lt;li&gt;安装EPEL源&lt;/li&gt;
&lt;li&gt;安装remi源&lt;/li&gt;
&lt;li&gt;配置remi源&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h1&gt;二.检测你的linux版本&lt;/h1&gt;
&lt;p&gt;由于不同Linux版本对应不同版本的Epel源，因此你需要首先确认你的Linux版本。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ lsb_release -a&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://ws1.sinaimg.cn/large/727cfec0gy1fm844kva8qj20fu02mglh.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;如图我的linux版本为6，那么我应该安装版本为6的Epel源。&lt;/p&gt;
&lt;h1&gt;三.安装Epel源&lt;/h1&gt;
&lt;p&gt;你可以打开这个&lt;a href=&quot;http://dl.fedoraproject.org/pub/epel/&quot;&gt;网址&lt;/a&gt;在里面找适合的epel源，我们可以在这个网站站到下面两个版本的源，根据需要下载对应的源即可。
下载该Epel源，然后安装即可，以linux6为例。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ wget http://dl.fedoraproject.org/pub/epel/epel-release-latest-6.noarch.rpm
$ rpm -ivh epel-release-latest-6.noarch.rpm&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;四.安装Remi源&lt;/h1&gt;
&lt;p&gt;操作和上面一样，到此&lt;a href=&quot;http://rpms.famillecollet.com/enterprise/&quot;&gt;网站&lt;/a&gt;找到适合的remi源即可，在首页能找到对应的版本6，然后wget下载并安装即可。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ wget http://rpms.famillecollet.com/enterprise/remi-release-6.rpm
$ rpm -ivh remi-release-6.rpm&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;五.修改remi源为允许的&lt;/h1&gt;
&lt;p&gt;在/etc/yum.repos.d/remi.repo修改里面的enable为1，除了test以外的，最后你就可以在yum安装里面使用上新版本的软件了。&lt;/p&gt;            </description>
            <pubDate>2019-10-01 09:05:00</pubDate>
            <link>//blog/PHP/remi.html</link>
            <guid isPermaLink="true">//blog/PHP/remi.html</guid>
                                               <category>Linux</category>
                                    </item>
                <item>
            <title>欢迎使用GitBlog</title>
            <description>
            &lt;!--
author: jockchou
head: http://pingodata.qiniudn.com/jockchou-avatar.jpg
date: 2015-07-31
title: 欢迎使用GitBlog
tags: GitBlog
images: http://pingodata.qiniudn.com/cube2.jpg
category: GitBlog
status: public
summary: GitBlog是一个简单易用的Markdown博客系统，它不需要数据库，没有管理后台功能，更新博客只需要添加你写好的Markdown文件即可。
--&gt;
&lt;h2&gt;一. 简介&lt;/h2&gt;
&lt;p&gt;GitBlog是一个简单易用的Markdown博客系统，它不需要数据库，没有管理后台功能，更新博客只需要添加你写好的Markdown文件即可。它摆脱了在线编辑器排版困难，无法实时预览的缺点，一切都交给Markdown来完成，一篇博客就是一个Markdown文件。同时也支持评论，代码高亮，数学公式，页面PV统计等常用功能。GitBlog提供了不同的主题样式，你可以根据自己的喜好配置，如果你想自己制作博客主题，也是非常容易的。GitBlog还支持整站静态导出，你完全可以导出整站静态网页部署到Github Pages。&lt;/p&gt;
&lt;h2&gt;二. 功能特点&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;使用Markdown  &lt;/li&gt;
&lt;li&gt;评论框  &lt;/li&gt;
&lt;li&gt;代码高亮  &lt;/li&gt;
&lt;li&gt;PV统计  &lt;/li&gt;
&lt;li&gt;Latex数学公式  &lt;/li&gt;
&lt;li&gt;自制主题  &lt;/li&gt;
&lt;li&gt;响应式  &lt;/li&gt;
&lt;li&gt;全站静态导出  &lt;/li&gt;
&lt;li&gt;良好的SEO  &lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;三. GitBlog优势&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;无需数据库，系统更轻量，移植更方便  &lt;/li&gt;
&lt;li&gt;使用Markdown编写，摆脱后台编辑排版困难，无法实时预览的缺点  &lt;/li&gt;
&lt;li&gt;可全站静态导出  &lt;/li&gt;
&lt;li&gt;配置灵活，可自由开关某些功能  &lt;/li&gt;
&lt;li&gt;多主题支持，可自制主题  &lt;/li&gt;
&lt;li&gt;博客，分类，标签，归档  &lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;四. 环境要求&lt;/h2&gt;
&lt;p&gt;PHP 5.2.4+&lt;/p&gt;
&lt;h2&gt;五. 安装步骤&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;下载GitBlog源代码  &lt;/li&gt;
&lt;li&gt;解压上传到你的PHP网站根目录  &lt;/li&gt;
&lt;li&gt;打开浏览器，访问网站首页  &lt;/li&gt;
&lt;li&gt;上传Markdown文件到&lt;code&gt;posts&lt;/code&gt;文件夹  &lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;六. 详细说明&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/jockchou/gitblogdoc/tree/master/posts/gitblog/install.md&quot;&gt;1. 安装&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://github.com/jockchou/gitblogdoc/tree/master/posts/gitblog/struct.md&quot;&gt;2. 目录结构&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://github.com/jockchou/gitblogdoc/tree/master/posts/gitblog/config.md&quot;&gt;3. 配置说明&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://github.com/jockchou/gitblogdoc/tree/master/posts/gitblog/edit.md&quot;&gt;4. 编写博客&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://github.com/jockchou/gitblogdoc/tree/master/posts/gitblog/other-func.md&quot;&gt;5. 评论，订阅，统计等&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://github.com/jockchou/gitblogdoc/tree/master/posts/gitblog/cache.md&quot;&gt;6. 缓存机制&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://github.com/jockchou/gitblogdoc/tree/master/posts/gitblog/export.md&quot;&gt;7. 全站静态导出&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://github.com/jockchou/gitblogdoc/tree/master/posts/gitblog/theme.md&quot;&gt;8. 主题制作&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://github.com/jockchou/gitblogdoc/tree/master/posts/gitblog/nginx.md&quot;&gt;9. 在Nginx上运行GitBlog&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://github.com/jockchou/gitblogdoc/tree/master/posts/gitblog/apache.md&quot;&gt;10. 在Apache上运行GitBlog&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://github.com/jockchou/gitblogdoc/tree/master/posts/gitblog/sae.md&quot;&gt;11. 在SAE上运行GitBlog&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://github.com/jockchou/gitblogdoc/tree/master/posts/gitblog/github-pages.md&quot;&gt;12. 使用GitBlog和Github Pages搭建博客&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://github.com/jockchou/gitblogdoc/tree/master/posts/gitblog/update.md&quot;&gt;13. Gitblog升级&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://github.com/jockchou/gitblogdoc/tree/master/posts/gitblog/wordpress.md&quot;&gt;14. 从wordpress导入&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;七. 问题及bug反馈&lt;/h2&gt;
&lt;p&gt;如果在实际使用过程中对GitBlog有新的功能需求，或者在使用GitBlog的过程中发现了Bug，欢迎反馈给我。可以直接在Github上提交，也可以发邮件至&lt;code&gt;164068300[AT]qq.com&lt;/code&gt;与我取得联系，我将及时回复。如果你自己制作了漂亮好用的主题，也非常欢迎你提交给我，我会在这里展示你的主题链接。如果你正在使用GitBlog，也可以告诉我，我将也会在这里列出使用者名单。如果你想和其他GitBlog使用者讨论交流，欢迎加入QQ群&lt;code&gt;84692078&lt;/code&gt;。&lt;/p&gt;
&lt;h2&gt;八. 使用者列表&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.hiweeds.net&quot;&gt;Weeds&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://xiaochengzi.sinaapp.com&quot;&gt;橙子&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://jockchou.com&quot;&gt;jockchou&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://github.com/jockchou/gitblogdoc&quot;&gt;GitBlog Doc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://zxy.link&quot;&gt;zxy&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;九. 感谢&lt;/h2&gt;
&lt;p&gt;GitBlog的成长需要喜欢Markdown，喜欢写博客的各位亲们支持！感谢你们使用GitBlog，感激你们对Gitblog的良好建议与Bug反馈。&lt;/p&gt;
&lt;p&gt;QQ群：&lt;code&gt;84692078&lt;/code&gt;&lt;br /&gt;
作者邮箱：&lt;code&gt;164068300[AT]qq.com&lt;/code&gt;    &lt;/p&gt;            </description>
            <pubDate>2019-10-01 09:05:00</pubDate>
            <link>//blog/welcome.html</link>
            <guid isPermaLink="true">//blog/welcome.html</guid>
                                               <category>GitBlog</category>
                                    </item>
            </channel>
</rss>